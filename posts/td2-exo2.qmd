---
title: "TD 2 - Exercice 2"
lang: fr
author: "Th√©o Leroy"
date: "17 septembre 2025"
params:
  question_courante: 3
format:
  live-html:
    code-background: true
    toc: true
    page-layout: full
webr:
  render-df: gt-interactive
fig-align: center
filters: 
  - diagram
  - custom-callout
editor: 
  mode: source
  markdown: 
    wrap: 72
custom-callout:    
  answer:
    color: "#CCCCCC"
    icon: true
    icon-symbol: "üìù"
    appearance: "default"
    title: "Correction"
---

{{< include ./../_extensions/conditionnal.qmd >}}
{{< include ./../_extensions/r-wasm/live/_knitr.qmd >}}

On consid√®re un mod√®le de r√©gression lin√©aire multiple
$y=X\beta+\epsilon$ o√π $\beta \in \mathbb{R}^p$, $X$ est une matrice de
taille $(n, p)$ et $\epsilon$ est un vecteur al√©atoire de taille $n$,
centr√© et de matrice de covariance $\sigma^2I_n$ ($I_n$ est la matrice
identit√©).

On d√©sire tester $q$ contraintes lin√©aires sur le param√®tre $\beta$,
c‚Äôest √† dire tester $H_0$ : $R\beta=0$ contre $H_1$ : $R\beta \neq0$, o√π
$R$ est une matrice de taille $(q, p)$.

On note $\textrm{SCR}$ la somme des carr√©s r√©siduelle du mod√®le initial,
et $\textrm{SCR}_c$ la somme des carr√©s r√©siduelle du mod√®le contraint
(c‚Äôest √† dire pour lequel l‚Äôhypoth√®se $H_0$ est v√©rifi√©e).

## Question 1

Rappeler la statistique utilis√©e pour effectuer ce test. On la notera
$F$ et on donnera son expression en fonction de $\textrm{SCR}$ et
$\textrm{SCR}_c$.

::: callout-tip
## Indications

Relire les slides 92 et 93 du cours
:::

::: {.content-visible when-meta="is_answer_print_1"}

::: answer
On utilise le test de Fisher. La statistique de test s‚Äô√©crit

$$
F=\frac{n-p}{q}\frac{\textrm{SCR}_c-\textrm{SCR}}{\textrm{SCR}}
$$
:::

:::

## Question 2

Quelle loi suit cette statistique sous $H_0$ lorsque $\epsilon$ suit une
loi normale ? Que peut-on dire de sa loi si aucune hypoth√®se de
normalit√© n‚Äôest faite sur $\epsilon$ ?

::: {.content-visible when-meta="is_answer_print_2"}

::: answer
Sous $H_0$ et si $\epsilon\sim\mathcal{N}(0,\sigma^2 I_n)$,

$$
F \sim F(q, n-p)
$$

Si on n‚Äôimpose pas l‚Äôhypoth√®se de normalit√©, il n‚Äôexiste en g√©n√©ral pas
de loi exacte $F(q,n-p)$ pour la statistique. Toutefois, sous quelques
conditions r√©guli√®res (erreurs i.i.d. de variance finie, conditions
d‚Äôidentifiabilit√©, $p$ fix√© et $n\to\infty$, etc.), on obtient un
r√©sultat asymptotique $F$ converge en loi vers $\tfrac{1}{q}\chi^2_q$.

En pratique, pour des √©chantillons de grande taille, le test de Fisher
reste donc valide approximativement m√™me sans normalit√© stricte des
$\epsilon$
:::

:::

## Question 3

Montrer que si une constante est pr√©sente dans le mod√®le contraint,

$$
F=\frac{R^2-R_c^2}{1-R^2}\frac{n-p}{q}
$$

o√π $R^2$ (respectivement $R_c^2$) d√©signe le coefficient de
d√©termination du mod√®le initial (respectivement du mod√®le contraint).

::: {.content-visible when-meta="is_answer_print_3"}

::: answer
Par d√©finition du coefficient de d√©termination (avec $\mathrm{SCT}$ la
somme totale des carr√©s et $\mathrm{SCE}$ la somme des carr√©s expliqu√©s)
:

$$
\begin{align*}
R^2&=\frac{\textrm{SCE}}{\textrm{SCT}}=1-\frac{\textrm{SCR}}{\textrm{SCT}} \\
R_c^2&=\frac{\textrm{SCE}_c}{\textrm{SCT}}=1-\frac{\textrm{SCR}_c}{\textrm{SCT}}
\end{align*}
$$ En rempla√ßant dans l‚Äôexpression du $F$ de la question 1 :

$$
F=\frac{n-p}{q}\frac{\textrm{SCR}_c-\textrm{SCR}}{\textrm{SCR}}=\frac{n-p}{q}\frac{(1-R_c^2)\textrm{SCT}-(1-R^2)\textrm{SCT}}{(1-R^2)\textrm{SCT}}=\frac{n-p}{q}\frac{R^2-R_c^2}{1-R^2}
$$
:::

:::
