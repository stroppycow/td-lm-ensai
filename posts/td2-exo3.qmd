---
title: "TD 2 - Exercice 3"
lang: fr
author: "Théo Leroy"
date: "8 octbre 2024"
format:
  live-html:
    code-background: true
    toc: true
    page-layout: full
webr:
  render-df: gt-interactive
  resources:
    - ./../data/icecream-R.dat
  packages:
      - tidyverse
      - car
      - GGally
      - rgl
fig-align: center
editor: 
  markdown: 
    wrap: 72
---

![](/static/img/icecream.jpg){fig-align="center"}

{{< include ./../_extensions/r-wasm/live/_knitr.qmd >}}

::::::::::::::::::::: {.content-hidden when-format="html"}
## Question 1

On charge les données du fichier `icecream-R.dat` en R sous forme de
`data.frame`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
data_icecream <- read.csv(
  file = "data/icecream-R.dat",
  header = TRUE,
  sep = "" # signifie un espace ou plus ou une tabulation
)
data_icecream
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
data_icecream <- readr::read_delim(
  file = "data/icecream-R.dat",
  col_types = "innii",
  col_names = c("Period", "Consumption", "Price", "Income", "Temp"),
  skip = 1,
  delim = "\t"
)
data_icecream
```
:::

Le fichier chargé contient bien 30 observations avec les variables :

-   `Period` pour la période (de la semaine 1 à la semaine 30)
-   `Consumption` pour la consommation moyenne de glaces par personne en
    1/2 litre (c'est la variable à expliquer)
-   `Price` pour le prix moyen des glaces en dollars
-   `Income` pour le salaire hebdomadaire moyen par ménage
-   `Temp` pour la température moyenne en degré Fahrenheit

On représente ces données dans des nuages de points.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
pairs(
  x = data_icecream[,-1],
  main = "Matrice des nuages de points sur les données de consommation de glaces"
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
GGally::ggpairs(
    data = data_icecream,
    columns  = c("Consumption", "Price", "Income", "Temp"),
    title = "Matrice des nuages de points sur les données de consommation de glaces",
    upper = list(continuous = "cor")
)
```
:::

Tracer tous les nuages de points 2 à 2 et pas seulement les nuages de
points avec la variable d’intérêt peut permettre de détecter des
problèmes de colinéarité. On note que ce potentiel phénomène n'est pas
présent ici.

Un lien linéaire semble exister ici entre la consommation de glaces et
la température, ce qui paraît assez naturel, mais il n'y a pas de
relation évidente avec les autres variables. De plus, il n'y a pas de
raison convaincante d'explorer une relation non-linéaire (carré, racine,
logarithme...).

## Question 2

On effectue la régression
$\texttt{Consumption}_i = \beta_1+\beta_2\texttt{Price}_i+\beta_3\texttt{Income}_i+\beta_4\texttt{Temp}_i+\varepsilon_i$
à l'aide de la fonction `lm` disponible nativement dans
{{< iconify logos:r-lang >}}. On cherche ainsi une estimation de
$\beta_1$, $\beta_2$, $\beta_3$ et $\beta_4$ à l'aide de la méthode des
moindres carrés ordinaires (MCO).

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
fit_lm_icecream <- lm(Consumption ~ Price + Income + Temp, data = data_icecream) 
summary(fit_lm_icecream)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
fit_lm_icecream <- lm(Consumption ~ Price + Income + Temp, data = data_icecream) 
summary(fit_lm_icecream)
```
:::

La première colonne de la partie notée <tt>Coefficients</tt> de la
sortie `summary` donne la valeur des coefficients estimés.

Sans regarder les valeurs, on peut d'abord observer les signes des
estimations comme le propose l'énoncé. La consommation semble décroître
avec l'augmentation du prix (signe négatif pour
$\widehat{\beta}_2 < 0$), augmenter avec les revenus des ménages (signe
positif $\widehat{\beta}_3 > 0$) et avec la température (signe positif
$\widehat{\beta}_4 > 0$).

Néanmoins, le coefficient $\widehat{\beta}_2$ n'est pas
significativement différent de 0 donc l'effet du prix sur la
consommation n'est donc pas confirmé. On ne devrait pas le commenter
(cf. question 4).

## Question 3

On teste $H_0: \ \beta_2 = \beta_3 = \beta_4 = 0$ contre
$H_1: \ \beta_2 \neq 0 \ \textrm{ou} \ \beta_3 \neq 0 \ \textrm{ou} \ \beta_4 \neq 0$
à l'aide d'un test de Fisher global. La dernière ligne de la sortie du
`summary` rend compte de ce test.

La p-value est bien inférieure à $0,05$ donc on rejette $H_0$. Ainsi, au
moins un coefficient (autre que la constante) est significatif.

## Question 4

On applique un test de Student de significativité à chaque coefficient
associé. C’est le test proposé dans la sortie
{{< iconify logos:r-lang >}} (troisième et quatrième colonne). A la
lecture des p-values par exemple, au seuil de 5 %, les variables
<tt>Income</tt> et <tt>Temp</tt> sont significatives (les p-values sont
inférieures à 0,05).

## Question 5

On estime un modèle sans la variable <tt>Price</tt>.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
fit_lm_icecream_without_price <- lm(Consumption ~ Income + Temp, data = data_icecream) 
summary(fit_lm_icecream_without_price)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
fit_lm_icecream_without_price <- lm(Consumption ~ Income + Temp, data = data_icecream) 
summary(fit_lm_icecream_without_price)
```
:::

**Test de Fisher en basant le calcul sur la somme des carrés résiduelle
de chaque modèle**

La statistique du test de Fisher vaut : $$
F=\frac{n-p}{q} \frac{SCR_c-SCR}{SCR}
$$

-   $n=30$ car il y a 30 observations
-   $p=4$ car il y a paramètres dans le modèle complet (trois variables
    plus la constante)
-   $q=1$ car il y a une seule contrainte dans le modèle contraint (le
    coefficient associé au prix est nul $\beta_{2}=0$)
-   $SCR$ est la somme des carrés des résidus $\widehat{\varepsilon}_i$
    dans le modèle complet et $SCR_c$ dans l'équivalent dans le modèle
    contraint

On compare cette statistique au quantile $0,95$ d'une loi de Fisher
$(q, \ n-p)$.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
F1 <- (nrow(data_icecream) - 4L)/1*(
  sum(fit_lm_icecream_without_price$residuals**2)/sum(fit_lm_icecream$residuals**2)-1)
F1
qf(p = 0.95, df1 = 1, df2 = nrow(data_icecream) - 4)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
F1 <- (nrow(data_icecream) - 4L)/1*(
  sum(fit_lm_icecream_without_price$residuals**2)/sum(fit_lm_icecream$residuals**2)-1)
F1
qf(p = 0.95, df1 = 1, df2 = nrow(data_icecream) - 4)
```
:::

On ne rejette pas $H_0$ car $F \leq q_{0,95}^{\mathcal{F}(q, \ n-p)}$
ainsi $\beta_2$ n'est pas significatif au seuil $5\ \%$.

**Test de Fisher en basant le calcul sur le coefficient de détermination
de chaque modèle**

On utilise la formule de $F$ faisant intervenir le $R^2$ déterminée à
l'exercice précédent.

$$
F=\frac{R^2-R_c^2}{1-R^2} \frac{n-p}{q}
$$

On relève dans les sorties des deux modèles : $R^2=0,719$ et
$R_c^2=0,7021$, ce qui se fait de façon automatique par

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
F2 <- (nrow(data_icecream) - 4L)/1*(
  summary(fit_lm_icecream)$r.squared -
  summary(fit_lm_icecream_without_price)$r.squared
)/(
  1 - summary(fit_lm_icecream)$r.squared
)
F2
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
F2 <- (nrow(data_icecream) - 4L)/1*(
  summary(fit_lm_icecream)$r.squared -
  summary(fit_lm_icecream_without_price)$r.squared
)/(
  1 - summary(fit_lm_icecream)$r.squared
)
F2
```
:::

**Test de Fisher en utilisant la fonction `linearHypothesis` de la
librairie `car`**

On renseigne la matrice de contrainte $R$ que l'on souhaite dans le test
$H_0: R \beta=0$. Il s'agit d'une matrice de taille $(q, p)$. Ici, on
souhaite simplement tester si $\beta_{2}=0$ c'est à dire si le deuxième
coefficient du vecteur $\beta$ est nul. La matrice $R$ est donc un
vecteur ligne valant $R=(0,1,0,0)$.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
car::linearHypothesis(fit_lm_icecream, c(0,1,0,0))
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
car::linearHypothesis(fit_lm_icecream, c(0,1,0,0))
```
:::

On ne rejette pas $H_0$ car la p-value est supérieure à $0,05$.

**Test de Fisher en utilisant la fonction `anova`**

De la même manière, la fonction `anova` permet de comparer deux modèles
emboités.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
anova(fit_lm_icecream, fit_lm_icecream_without_price)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
anova(fit_lm_icecream, fit_lm_icecream_without_price)
```
:::

La significativité d’un seul coefficient est équivalent au test de
Student associé, on a d'ailleurs $T_2^2=F$.

## Question 6

On estime un modèle sans la variable <tt>Price</tt> et la constante. On
teste
$$H_0: \ \beta_1 = \beta_2  = 0 \textrm{ contre } H_1: \ \beta_1 \neq 0 \ \textrm{ou} \ \beta_2 \neq 0$$

On a $q=2$ désormais.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
fit_lm_icecream_without_price_and_intercept <- lm(
  Consumption ~ Income + Temp -1L,
  data = data_icecream
) 
summary(fit_lm_icecream_without_price_and_intercept)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
fit_lm_icecream_without_price_and_intercept <- lm(
  Consumption ~ Income + Temp -1L,
  data = data_icecream
) 
summary(fit_lm_icecream_without_price_and_intercept)
```
:::

**Test de Fisher en basant le calcul sur la somme des carrés résiduelle
de chaque modèle**

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
F1 <- (nrow(data_icecream) - 4L)/2*(
  sum(fit_lm_icecream_without_price_and_intercept$residuals**2)/sum(fit_lm_icecream$residuals**2)-1)
F1
qf(p = 0.95, df1 = 2, df2 = nrow(data_icecream) - 4)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
F1 <- (nrow(data_icecream) - 4L)/2*(
  sum(fit_lm_icecream_without_price_and_intercept$residuals**2)/sum(fit_lm_icecream$residuals**2)-1)
F1
qf(p = 0.95, df1 = 2, df2 = nrow(data_icecream) - 4)
```
:::

On ne rejette pas $H_0$ car $F \leq q_{0,95}^{\mathcal{F}(q, \ n-p)}$
ainsi $\beta_1$ et $\beta_2$ ne sont pas significatifs au seuil $5\ \%$.

**Test de Fisher en basant le calcul sur le coefficient de détermination
de chaque modèle**

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
F2 <- (nrow(data_icecream) - 4L)/2*(
  summary(fit_lm_icecream)$r.squared -
  summary(fit_lm_icecream_without_price_and_intercept)$r.squared
)/(
  1 - summary(fit_lm_icecream)$r.squared
)
F2
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
F2 <- (nrow(data_icecream) - 4L)/2*(
  summary(fit_lm_icecream)$r.squared -
  summary(fit_lm_icecream_without_price_and_intercept)$r.squared
)/(
  1 - summary(fit_lm_icecream)$r.squared
)
F2
```
:::

La valeur de $F$ obtenue n'est pas la même. Celle-ci n'est pas bonne car
la formule utilisée n’est pas valable : l’expression avec le $R^2$ n’est
bonne que si la constante est présente dans les deux modèles (le
contraint et le non contraint), ce qui n’est pas le cas ici.

**Test de Fisher en utilisant la fonction `linearHypothesis` de la
librairie `car`**

La matrice $R$ vaut désormais

$$
R=\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
\end{pmatrix}
$$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
car::linearHypothesis(
  fit_lm_icecream,
  matrix(c(1, 0, 0, 0, 0, 1, 0, 0), nrow = 2, byrow = TRUE)
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
car::linearHypothesis(
  fit_lm_icecream,
  matrix(c(1, 0, 0, 0, 0, 1, 0, 0), nrow = 2, byrow = TRUE)
)
```
:::

On ne rejette pas $H_0$ car la p-value est supérieure à $0,05$.

**Test de Fisher en utilisant la fonction `anova`**

De la même manière, la fonction `anova` permet de comparer deux modèles
emboités.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
anova(
  fit_lm_icecream,
  fit_lm_icecream_without_price_and_intercept
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
anova(
  fit_lm_icecream,
  fit_lm_icecream_without_price_and_intercept
)
```
:::

## Question 7

D'après la question précédente, le modèle sans la constante et le
coefficient associé à la variable prix semble meilleur (car significatif
et plus parcimonieux)

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
newdata <- data.frame(Income = 85,Temp = 65)
predict(
  object = fit_lm_icecream_without_price_and_intercept,
  newdata = newdata,
  interval = "prediction"
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
newdata <- data.frame(Income = 85,Temp = 65)
predict(
  object = fit_lm_icecream_without_price_and_intercept,
  newdata = newdata,
  interval = "prediction"
)
```
:::

On prédit une consommation de $0,41$ avec $IC = [0,33; \ 0,49]$ à
$95\ \%$.

## Question 8

L'intervalle de prévision est valable uniquement sous hypothèse
gaussienne.

On peut examiner cette hypothèse avec un QQ-plot ou avec le test de
Shapiro-Wilk.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
qqnorm(fit_lm_icecream_without_price_and_intercept$residuals)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
qqnorm(fit_lm_icecream_without_price_and_intercept$residuals)
```
:::

Même si le diagramme quantile-quantile n'est pas très convaincant, le
test de Shapiro Wilk ne permet pas de rejeter l’hypothèse nulle de
Gaussianité des résidus.

## Question 9

**Analyse de l'absence de multicolinéarité**

Le VIF pour la variable $X^{(j)}$ vaut $$
VIF_j=\frac{1}{1-R_j^2}
$$ où $R_j^2$ est le $R^2$ dans la régression de $X^{(j)}$ par rapport
aux autres variables explicatives. $R_j^2$ peut être vu comme la mesure
de la corrélation entre $X^{(j)}$ est les autres variables, de telle
sorte que $VIF_j$ explose si $R_j^2$ est proche de 1 , c'est à dire s'il
y a un problème de multicolinéarité entre la variable $X^{(j)}$ et les
autres variables. On a toujours $VIF_j \geq 1$ et on considère qu'il y a
un problème de multicolinéarité lorsque $VIF_j>5$ (ce seuil n'est pas
strict, c'est juste un seuil d'alerte).

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
qqnorm(fit_lm_icecream_without_price_and_intercept$residuals)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
qqnorm(fit_lm_icecream_without_price_and_intercept$residuals)
```
:::

**Analyse de l'absence des résidus**

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
par(mfrow= c(2, 2))
plot(fit_lm_icecream_without_price_and_intercept)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
par(mfrow= c(2, 2))
plot(fit_lm_icecream_without_price_and_intercept)
```
:::

## Question 10

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
car::scatter3d(
  data_icecream$Income,
  data_icecream$Consumption,
  data_icecream$Temp,
  surface = TRUE
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
car::scatter3d(
  data_icecream$Income,
  data_icecream$Consumption,
  data_icecream$Temp,
  surface = TRUE
)
```
:::
:::::::::::::::::::::
