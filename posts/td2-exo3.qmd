---
title: "TD 2 - Exercice 3"
lang: fr
author: "Théo Leroy"
date: "17 septembre 2025"
format:
  live-html:
    code-background: true
    toc: true
    page-layout: full
webr:
  render-df: gt-interactive
  resources:
    - ./../data/icecream-R.dat
  packages:
      - tidyverse
      - car
      - GGally
      - scatterplot3d
      - rgl
fig-align: center
filters: 
  - diagram
  - custom-callout
editor: 
  markdown: 
    wrap: 72
custom-callout:    
  answer:
    color: "#CCCCCC"
    appearance: "minimal"
    title: ""
---

![](/static/img/icecream.jpg){fig-align="center"}

{{< include ./../_extensions/r-wasm/live/_knitr.qmd >}}

On étudie la consommation de glaces aux Etats-Unis sur une période de 30 semaines
du 18 Mars 1950 au 11 Juillet 1953. Les variables sont la période (de la semaine 1 à la semaine 30), et en moyenne sur chaque période : la consommation de glaces par personne (`Consumption`, en 1/2 litre), le prix des glaces (`Price`, en dollars), le salaire hebdomadaire moyen par ménage (`Income`, en dollars), et la température (`Temp`, en degré Fahrenheit). Les données sont disponibles dans le fichier `icecream-R.dat`.

## Question 1

Extraire les données et représenter la consommation en fonction des différentes variables.

::: answer

On charge les données du fichier `icecream-R.dat` en R sous forme de
`data.frame`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
data_icecream <- read.csv(
  file = "data/icecream-R.dat",
  header = TRUE,
  sep = "" # signifie un espace ou plus ou une tabulation
)
data_icecream
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
data_icecream <- readr::read_delim(
  file = "data/icecream-R.dat",
  col_types = "innii",
  col_names = c("Period", "Consumption", "Price", "Income", "Temp"),
  skip = 1,
  delim = "\t"
)
data_icecream
```
:::

Le fichier chargé contient bien 30 observations avec les variables :

-   `Period` pour la période (de la semaine 1 à la semaine 30)
-   `Consumption` pour la consommation moyenne de glaces par personne en
    1/2 litre (c'est la variable à expliquer)
-   `Price` pour le prix moyen des glaces en dollars
-   `Income` pour le salaire hebdomadaire moyen par ménage
-   `Temp` pour la température moyenne en degré Fahrenheit

On représente ces données dans des nuages de points.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
pairs(
  x = data_icecream[,-1],
  main = "Matrice des nuages de points sur les données de consommation de glaces"
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
GGally::ggpairs(
    data = data_icecream,
    columns  = c("Consumption", "Price", "Income", "Temp"),
    title = "Matrice des nuages de points sur les données de consommation de glaces",
    upper = list(continuous = "cor")
)
```
:::

Tracer tous les nuages de points 2 à 2 et pas seulement les nuages de
points avec la variable d’intérêt peut permettre de détecter des
problèmes de colinéarité. On note que ce potentiel phénomène n'est pas
présent ici.

Un lien linéaire semble exister ici entre la consommation de glaces et
la température, ce qui paraît assez naturel, mais il n'y a pas de
relation évidente avec les autres variables. De plus, il n'y a pas de
raison convaincante d'explorer une relation non-linéaire (carré, racine,
logarithme...).

:::

## Question 2

On propose de régresser linéairement la consommation sur les trois variables `Price`, `Income` et `Temp`, en supposant de plus qu’une constante est présente dans le modèle. On note la constante $\beta_1$ et les trois coefficients associés aux variables précédentes respectivement $\beta_2$, $\beta_3$ et $\beta_4$. Réaliser la phase d’estimation de cette régression et commenter le signe des coefficients estimés.

::: answer

On effectue la régression
$\texttt{Consumption}_i = \beta_1+\beta_2\texttt{Price}_i+\beta_3\texttt{Income}_i+\beta_4\texttt{Temp}_i+\varepsilon_i$
à l'aide de la fonction `lm` disponible nativement dans
{{< iconify logos:r-lang >}}. On cherche ainsi une estimation de
$\beta_1$, $\beta_2$, $\beta_3$ et $\beta_4$ à l'aide de la méthode des
moindres carrés ordinaires (MCO).

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
fit_lm_icecream <- lm(Consumption ~ Price + Income + Temp, data = data_icecream) 
summary(fit_lm_icecream)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
fit_lm_icecream <- lm(Consumption ~ Price + Income + Temp, data = data_icecream) 
summary(fit_lm_icecream)
```
:::

La première colonne de la partie notée <tt>Coefficients</tt> de la
sortie `summary` donne la valeur des coefficients estimés.

Sans regarder les valeurs, on peut d'abord observer les signes des
estimations comme le propose l'énoncé. La consommation semble décroître
avec l'augmentation du prix (signe négatif pour
$\widehat{\beta}_2 < 0$), augmenter avec les revenus des ménages (signe
positif $\widehat{\beta}_3 > 0$) et avec la température (signe positif
$\widehat{\beta}_4 > 0$).

Néanmoins, le coefficient $\widehat{\beta}_2$ n'est pas
significativement différent de 0 donc l'effet du prix sur la
consommation n'est donc pas confirmé. On ne devrait pas le commenter
(cf. question 4).

:::

## Question 3

Tester la significativité globale du modèle proposé, i.e. $H_0 \ : \ \beta_2=\beta_3=\beta_4=0$ à l’aide du test de Fisher global.

::: answer

On teste $H_0: \ \beta_2 = \beta_3 = \beta_4 = 0$ contre
$H_1: \ \beta_2 \neq 0 \ \textrm{ou} \ \beta_3 \neq 0 \ \textrm{ou} \ \beta_4 \neq 0$
à l'aide d'un test de Fisher global. La dernière ligne de la sortie du
`summary` rend compte de ce test.

La p-value est bien inférieure à $0,05$ donc on rejette $H_0$. Ainsi, au
moins un coefficient (autre que la constante) est significatif.

:::

## Question 4

Tester la significativité de la variable `Price` dans ce modèle au seuil de 5 %. Tester de même la significativité de `Income`, puis de `Temp`.

::: answer

On applique un test de Student de significativité à chaque coefficient
associé. C’est le test proposé dans la sortie
{{< iconify logos:r-lang >}} (troisième et quatrième colonne). A la
lecture des p-values par exemple, au seuil de 5 %, les variables
<tt>Income</tt> et <tt>Temp</tt> sont significatives (les p-values sont
inférieures à 0,05).

:::

## Question 5

Comparer le modèle complet précédent et le modèle sans la variable `Price` à l’aide d’un test de Fisher :

  1. En basant le calcul sur la somme des carrés résiduelle de chaque modèle ;
  2. En basant le calcul sur le coefficient de détermination de chaque modèle ;
  3. En utilisant la fonction `linearHypothesis`  de la librairie `car` ;
  4. En utilisant la fonction anova.
  
Quel est la différence entre ce test et le test de Student de significativité de la variable `Price` ?

::: answer

On estime un modèle sans la variable <tt>Price</tt>.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
fit_lm_icecream_without_price <- lm(Consumption ~ Income + Temp, data = data_icecream) 
summary(fit_lm_icecream_without_price)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
fit_lm_icecream_without_price <- lm(Consumption ~ Income + Temp, data = data_icecream) 
summary(fit_lm_icecream_without_price)
```

:::

**Test de Fisher en basant le calcul sur la somme des carrés résiduelle
de chaque modèle**

La statistique du test de Fisher vaut : $$
F=\frac{n-p}{q} \frac{SCR_c-SCR}{SCR}
$$

-   $n=30$ car il y a 30 observations
-   $p=4$ car il y a paramètres dans le modèle complet (trois variables
    plus la constante)
-   $q=1$ car il y a une seule contrainte dans le modèle contraint (le
    coefficient associé au prix est nul $\beta_{2}=0$)
-   $SCR$ est la somme des carrés des résidus $\widehat{\varepsilon}_i$
    dans le modèle complet et $SCR_c$ dans l'équivalent dans le modèle
    contraint

On compare cette statistique au quantile $0,95$ d'une loi de Fisher
$(q, \ n-p)$.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
F1 <- (nrow(data_icecream) - 4L)/1*(
  sum(fit_lm_icecream_without_price$residuals**2)/sum(fit_lm_icecream$residuals**2)-1)
F1
qf(p = 0.95, df1 = 1, df2 = nrow(data_icecream) - 4)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
F1 <- (nrow(data_icecream) - 4L)/1*(
  sum(fit_lm_icecream_without_price$residuals**2)/sum(fit_lm_icecream$residuals**2)-1)
F1
qf(p = 0.95, df1 = 1, df2 = nrow(data_icecream) - 4)
```

:::

On ne rejette pas $H_0$ car $F \leq q_{0,95}^{\mathcal{F}(q, \ n-p)}$
ainsi $\beta_2$ n'est pas significatif au seuil $5\ \%$.

**Test de Fisher en basant le calcul sur le coefficient de détermination
de chaque modèle**

On utilise la formule de $F$ faisant intervenir le $R^2$ déterminée à
l'exercice précédent.

$$
F=\frac{R^2-R_c^2}{1-R^2} \frac{n-p}{q}
$$

On relève dans les sorties des deux modèles : $R^2=0,719$ et
$R_c^2=0,7021$, ce qui se fait de façon automatique par

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
F2 <- (nrow(data_icecream) - 4L)/1*(
  summary(fit_lm_icecream)$r.squared -
  summary(fit_lm_icecream_without_price)$r.squared
)/(
  1 - summary(fit_lm_icecream)$r.squared
)
F2
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
F2 <- (nrow(data_icecream) - 4L)/1*(
  summary(fit_lm_icecream)$r.squared -
  summary(fit_lm_icecream_without_price)$r.squared
)/(
  1 - summary(fit_lm_icecream)$r.squared
)
F2
```

:::

**Test de Fisher en utilisant la fonction `linearHypothesis` de la
librairie `car`**

On renseigne la matrice de contrainte $R$ que l'on souhaite dans le test
$H_0: R \beta=0$. Il s'agit d'une matrice de taille $(q, p)$. Ici, on
souhaite simplement tester si $\beta_{2}=0$ c'est à dire si le deuxième
coefficient du vecteur $\beta$ est nul. La matrice $R$ est donc un
vecteur ligne valant $R=(0,1,0,0)$.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
car::linearHypothesis(fit_lm_icecream, c(0,1,0,0))
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
car::linearHypothesis(fit_lm_icecream, c(0,1,0,0))
```
:::

On ne rejette pas $H_0$ car la p-value est supérieure à $0,05$.

**Test de Fisher en utilisant la fonction `anova`**

De la même manière, la fonction `anova` permet de comparer deux modèles
emboités.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
anova(fit_lm_icecream, fit_lm_icecream_without_price)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
anova(fit_lm_icecream, fit_lm_icecream_without_price)
```
:::

La significativité d’un seul coefficient est équivalent au test de
Student associé, on a d'ailleurs $T_2^2=F$.

:::

## Question 6

Comparer le modèle complet et le modèle sans la variable "Price" et sans la constante à l’aide d’un test de Fisher. Procéder selon les 4 manières décrites ci-dessus.

Commenter.

::: answer


On estime un modèle sans la variable <tt>Price</tt> et la constante. On
teste
$$H_0: \ \beta_1 = \beta_2  = 0 \textrm{ contre } H_1: \ \beta_1 \neq 0 \ \textrm{ou} \ \beta_2 \neq 0$$

On a $q=2$ désormais.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
fit_lm_icecream_without_price_and_intercept <- lm(
  Consumption ~ Income + Temp -1L,
  data = data_icecream
) 
summary(fit_lm_icecream_without_price_and_intercept)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
fit_lm_icecream_without_price_and_intercept <- lm(
  Consumption ~ Income + Temp -1L,
  data = data_icecream
) 
summary(fit_lm_icecream_without_price_and_intercept)
```
:::

**Test de Fisher en basant le calcul sur la somme des carrés résiduelle
de chaque modèle**

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
F1 <- (nrow(data_icecream) - 4L)/2*(
  sum(fit_lm_icecream_without_price_and_intercept$residuals**2)/sum(fit_lm_icecream$residuals**2)-1)
F1
qf(p = 0.95, df1 = 2, df2 = nrow(data_icecream) - 4)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
F1 <- (nrow(data_icecream) - 4L)/2*(
  sum(fit_lm_icecream_without_price_and_intercept$residuals**2)/sum(fit_lm_icecream$residuals**2)-1)
F1
qf(p = 0.95, df1 = 2, df2 = nrow(data_icecream) - 4)
```
:::

On ne rejette pas $H_0$ car $F \leq q_{0,95}^{\mathcal{F}(q, \ n-p)}$
ainsi $\beta_1$ et $\beta_2$ ne sont pas significatifs au seuil $5\ \%$.

**Test de Fisher en basant le calcul sur le coefficient de détermination
de chaque modèle**

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
F2 <- (nrow(data_icecream) - 4L)/2*(
  summary(fit_lm_icecream)$r.squared -
  summary(fit_lm_icecream_without_price_and_intercept)$r.squared
)/(
  1 - summary(fit_lm_icecream)$r.squared
)
F2
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
F2 <- (nrow(data_icecream) - 4L)/2*(
  summary(fit_lm_icecream)$r.squared -
  summary(fit_lm_icecream_without_price_and_intercept)$r.squared
)/(
  1 - summary(fit_lm_icecream)$r.squared
)
F2
```

:::

La valeur de $F$ obtenue n'est pas la même. Celle-ci n'est pas bonne car
la formule utilisée n’est pas valable : l’expression avec le $R^2$ n’est
bonne que si la constante est présente dans les deux modèles (le
contraint et le non contraint), ce qui n’est pas le cas ici.

**Test de Fisher en utilisant la fonction `linearHypothesis` de la
librairie `car`**

La matrice $R$ vaut désormais

$$
R=\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
\end{pmatrix}
$$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
car::linearHypothesis(
  fit_lm_icecream,
  matrix(c(1, 0, 0, 0, 0, 1, 0, 0), nrow = 2, byrow = TRUE)
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
car::linearHypothesis(
  fit_lm_icecream,
  matrix(c(1, 0, 0, 0, 0, 1, 0, 0), nrow = 2, byrow = TRUE)
)
```

:::

On ne rejette pas $H_0$ car la p-value est supérieure à $0,05$.

**Test de Fisher en utilisant la fonction `anova`**

De la même manière, la fonction `anova` permet de comparer deux modèles
emboités.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
anova(
  fit_lm_icecream,
  fit_lm_icecream_without_price_and_intercept
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
anova(
  fit_lm_icecream,
  fit_lm_icecream_without_price_and_intercept
)
```

:::

:::

## Question 7

On désire à présent prédire la consommation de glaces pour les données suivantes :
`Price = 0.3`, `Income = 85` et `Temp = 65`. Proposer la prévision qui vous semble la meilleure au vu des modèles étudiés précédemment. Donner un intervalle de prévision au niveau 95 % autour de cette prévision.

::: answer

D'après la question précédente, le modèle sans la constante et le
coefficient associé à la variable prix semble meilleur (car significatif
et plus parcimonieux)

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
newdata <- data.frame(Income = 85,Temp = 65)
predict(
  object = fit_lm_icecream_without_price_and_intercept,
  newdata = newdata,
  interval = "prediction"
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
newdata <- data.frame(Income = 85,Temp = 65)
predict(
  object = fit_lm_icecream_without_price_and_intercept,
  newdata = newdata,
  interval = "prediction"
)
```

:::

On prédit une consommation de $0,41$ avec $IC = [0,33; \ 0,49]$ à
$95\ \%$.

:::

## Question 8

Sous quelle hypothèse l’intervalle de prévision précédent est-il valable ? Vérifier-la en observant le QQ-plot des résidus de la régression et en effectuant un test statistique.

::: answer

L'intervalle de prévision est valable uniquement sous hypothèse
gaussienne.

On peut examiner cette hypothèse avec un QQ-plot ou avec le test de
Shapiro-Wilk.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
qqnorm(fit_lm_icecream_without_price_and_intercept$residuals)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
qqnorm(fit_lm_icecream_without_price_and_intercept$residuals)
```

:::

Même si le diagramme quantile-quantile n'est pas très convaincant, le
test de Shapiro Wilk ne permet pas de rejeter l’hypothèse nulle de
Gaussianité des résidus.

:::

## Question 9

Vérifier les autres hypothèses en rappelant la définition et en calculant les VIF ("Variance Inflation Factor") de chaque variable explicative et en effectuant une analyse graphique des résidus.

::: answer

**Analyse de l'absence de multicolinéarité**

Le VIF pour la variable $X^{(j)}$ vaut $$
VIF_j=\frac{1}{1-R_j^2}
$$ où $R_j^2$ est le $R^2$ dans la régression de $X^{(j)}$ par rapport
aux autres variables explicatives. $R_j^2$ peut être vu comme la mesure
de la corrélation entre $X^{(j)}$ est les autres variables, de telle
sorte que $VIF_j$ explose si $R_j^2$ est proche de 1 , c'est à dire s'il
y a un problème de multicolinéarité entre la variable $X^{(j)}$ et les
autres variables. On a toujours $VIF_j \geq 1$ et on considère qu'il y a
un problème de multicolinéarité lorsque $VIF_j>5$ (ce seuil n'est pas
strict, c'est juste un seuil d'alerte).

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
car::vif(fit_lm_icecream)
car::vif(fit_lm_icecream_without_price)
car::vif(fit_lm_icecream_without_price_and_intercept)

```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
car::vif(fit_lm_icecream)
car::vif(fit_lm_icecream_without_price)
car::vif(fit_lm_icecream_without_price_and_intercept)

```
:::

On constate que les VIF dans le modèle global ne sont pas élevés (le
plus grand étant de 1,14), ce qui indique l'absence de colinéarité entre
les variables explicatives. Cette observation est cohérente avec les
nuages de points analysés au début de l'exercice, qui ne montraient pas
de relations fortes entre ces variables.

Cette conclusion est également confirmée par le calcul des VIF pour le
sous-modèle `fit_lm_icecream_without_price`, car si aucune colinéarité
n'existe dans un modèle, elle ne peut pas apparaître dans un
sous-modèle.

En revanche, le résultat est différent pour le sous-modèle
`fit_lm_icecream_without_price_and_intercept`, car celui-ci ne comporte
pas de constante. Par conséquent, les $R_j^2$ utilisés dans le calcul
des $VIF_j$ ne se basent pas sur la formule habituelle du $R^2$, mais
sur une version sans constante, qui est différente. En particulier, le
$R^2$ sans constante est souvent beaucoup plus élevé que le $R^2$ avec
constante (voir exercice 4), ce qui explique l'augmentation
significative des VIF dans ce cas. Un avertissement dans R signale ce
problème. En conclusion, il ne faut pas calculer les VIF dans un modèle
sans constante. L'analyse réalisée sur le modèle global (ainsi que sur
le sous-modèle `fit_lm_icecream_without_price`) garantit qu'il n'y a pas
de problème de colinéarité entre les variables explicatives.

**Analyse des résidus**

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
par(mfrow= c(2, 2))
plot(fit_lm_icecream_without_price_and_intercept)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
par(mfrow= c(2, 2))
plot(fit_lm_icecream_without_price_and_intercept)
```
:::

On peut réaliser une analyse graphique rapide des résidus en utilisant
la fonction plot sur le modèle estimé. Quatre graphiques sont générés.
Le premier montre la répartition des résidus en fonction des valeurs
ajustées $\widehat{y}_i$ : les résidus sont ici distribués de manière
aléatoire, sans structure apparente, ce qui est attendu pour des résidus
"corrects". Le deuxième graphique est le QQ-plot des résidus, que nous
avons déjà réalisé. Le troisième graphique est similaire au premier et
n'apporte généralement pas beaucoup d'informations supplémentaires.
Enfin, le quatrième graphique permet d'identifier des individus
aberrants ou trop influents pour l'estimation : s'il n'y a pas de points
isolés (ce qui est le cas ici), il n'y a pas de problème particulier.
Dans ce dernier graphique, on voit des pointillés en haut à droite,
correspondant à la ligne de niveau de la distance de Cook, qui a une
forme d'hyperbole. Si un point se trouve au-delà de ces pointillés, cela
indiquerait qu'il est influent et/ou aberrant, mais ce n'est pas le cas
ici.

:::

## Question 10

Observer le nuage de points en 3D des variables `Consumption`, `Income` et `Temp`,
et l’ajustement par le modèle linéaire, à l’aide de `scatter3d` de la librairie `car`.

::: answer

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
car::scatter3d(
  data_icecream$Income,
  data_icecream$Consumption,
  data_icecream$Temp
)
rgl::rglwidget()
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
car::scatter3d(
  data_icecream$Income,
  data_icecream$Consumption,
  data_icecream$Temp
)
rgl::rglwidget()
```

:::

:::
