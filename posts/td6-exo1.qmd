---
title: "TD 6 - Exercice 1 - Maladie coronarienne"
lang: fr
author: "Th√©o Leroy"
date: "14 novembre 2025"
params:
  question_courante: 20
format:
  live-html:
    code-background: true
    toc: true
    page-layout: full
webr:
  render-df: gt-interactive
  resources:
    - ./../data/chdage.txt
  packages:
      - dplyr
      - readr
      - ggplot2
      - cowplot
      - GGally
      - car
      - leaps
      - lmtest
editor: 
  mode: source
  markdown: 
    wrap: 72
fig-align: center
filters: 
  - custom-callout
custom-callout:    
  answer:
    color: "#CCCCCC"
    icon: true
    icon-symbol: "üìù"
    appearance: "default"
    title: "Correction"
---

{{< include ./../_extensions/conditionnal.qmd >}}
{{< include ./../_extensions/r-wasm/live/_knitr.qmd >}}

Le jeu de donn√©e `chdage.txt`, contient les donn√©es
de 100 patients √¢g√©s de 20 √† 69 ans (variable $\texttt{age}$), pr√©sentant pour certains une maladie coronarienne (variable $\texttt{chd}$ valant $\texttt{Yes}$ ou $\texttt{No}$).

## Question 1

Importer ces donn√©es sous {{< iconify logos:r-lang >}} sous la forme d‚Äôun `data.frame`. Observer le contenu de chaque variable et transformer leur `class` si n√©cessaire.

::: {.content-visible when-meta="is_answer_print_1"}

::: answer

On charge les donn√©es du fichier `chdage.txt` en {{< iconify logos:r-lang >}} sous forme de
`data.frame`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
data_chdage <- read.csv(
  file = "data/chdage.txt",
  header = TRUE,
  sep = " ",
  colClasses = c("id"="integer", "age"="integer", "agegrp"="factor", "chd"="factor")
)
data_chdage
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
data_chdage <- readr::read_delim(
  file = "data/chdage.txt",
  col_names = c("id", "age", "agegrp", "chd"),
  col_types = readr::cols(
    readr::col_skip(),
    readr::col_integer(),
    readr::col_integer(),
    readr::col_factor(),
    readr::col_factor()
  ),
  delim = " ",
  skip = 1
)
data_chdage
```
:::

:::

:::

## Question 2

Proposer une ou des visualisation(s) graphique(s) permettant d‚Äôanalyser le lien √©ventuel
entre les variables $\texttt{chd}$ et $\texttt{age}$.

::: {.content-visible when-meta="is_answer_print_2"}

::: answer

Une possibilit√© est de visualiser les donn√©es sous forme de bo√Ætes √†
moustache pour comparer les distributions de l'√¢ge des individus dans
les populations ayant ou non une maladie coronarienne.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
boxplot(age ~ chd, data = data_chdage)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
ggplot2::ggplot(data = data_chdage, mapping = ggplot2::aes(x=chd, y=age)) +
  ggplot2::geom_boxplot(fill='#F2F2F2') +
  ggplot2::labs(x="Pr√©sence de maladie coronarienne", y="√Çge") +
  ggplot2::scale_x_discrete(labels = c("Yes"="Oui", "No"="Non")) +
  ggplot2::theme_light() 
```
:::

::: {.callout-note collapse="true"}
### Rappel sur les diagrammes en bo√Æte

La bo√Æte √† moustaches r√©sume seulement quelques indicateurs de position
sur une variable quantitative. Le *package* `ggplot2` repr√©sente les
statistiques ci-dessous :

![](/static/img/boxplot.svg){fig-align="center"}
:::

On peut √©galement repr√©senter la proportion d'individus malades par
classe d'√¢ge.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
# Calcul des proportions par groupe d'√¢ge
prop_data <- prop.table(table(data_chdage$chd,data_chdage$agegrp), margin= 2) |> as.data.frame()
colnames(prop_data) <- c("chd", "agegrp", "prop")
prop_data <- tapply(prop_data$prop, list(prop_data$chd, prop_data$agegrp), identity)

# Couleurs pour les barres
fill_colors <- c("Yes" = "#F24B4B", "No" = "#F2F2F2")

# Graphique
barplot(
  height = prop_data[c(2,1), ],
  beside = FALSE, # Empil√©
  col = fill_colors,
  border = "white",
  horiz = TRUE, # Barres horizontales
  xlab = "Proportion",
  ylab = "Cat√©gorie d'√¢ge",
  las = 1
)

# L√©gende
legend(
  "bottom", 
  legend = c("Oui", "Non"), 
  fill = fill_colors,
  bty = "n", 
  title = "Atteint par une maladie coronarienne", 
  horiz = TRUE
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
ggplot2::ggplot(
  data = data_chdage,
  mapping = ggplot2::aes(y = agegrp, fill = chd)
) +
  ggplot2::geom_bar(, position = "fill") +
  ggplot2::labs(
    x = "Proportion",
    y = "Cat√©gorie d'√¢ge",
    fill = "Pr√©sence de maladie coronarienne"
  ) +
  ggplot2::scale_fill_manual(
    values = c("Yes"="#F24B4B", "No"="#F2F2F2"),
    labels = c("Yes"="Oui", "No"="Non"),
    name = "Atteint par une maladie coronarienne"
  ) +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "bottom")
```
:::

:::

:::

## Question 3

Un lien est-t-il apparent ? Quel test statistique simple permettrait de le confirmer ?

::: {.content-visible when-meta="is_answer_print_3"}

::: answer

Dans la question pr√©c√©dente, on observe graphiquement que les individus
malades sont plus √¢g√©s que les individus sains. On souhaiterait tester
si cette diff√©rence est significative. Un test simple √† mettre en place
est le test de Student pour comparer deux moyennes dans des
√©chantillons.

$$H_0: \mu_{\textrm{malade}} = \mu_{\textrm{sain}} $$

$$H_1: \mu_{\textrm{malade}} \neq \mu_{\textrm{sain}} $$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
t.test(age ~ chd, data = data_chdage, var.equal = TRUE)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
t.test(age ~ chd, data = data_chdage, var.equal = TRUE)
```
:::

On rejette l'hypoth√®se nulle au seuil 5¬†%. Les moyennes d'√¢ge des deux
populations sont diff√©rentes.

N√©anmoins, ce test est valable pour des lois normales avec des variances
√©gales. Regardons graphiquement si ces conditions sont v√©rifi√©es.

::::: panel-tabset
### Histogramme

::: {.panel-tabset group="language"}
#### Base R

```{webr}
#| envir: baser
#| autorun: true
# Pr√©parer les facettes : diviser les donn√©es par la variable `chd`
data_split <- split(data_chdage, data_chdage$chd)

# Configurer les facettes avec `par()`
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1)) # 2 lignes, 1 colonne

# Histogramme pour les individus malades ("Yes")
hist(
  data_split$Yes$age, breaks = seq(20, 85, by = 5), col = "#F24B4B", border = "black",
  main = "Individus malades", xlab = "√Çge", ylab = "Effectif", xlim = c(20, 85)
)

# Histogramme pour les individus sains ("No")
hist(
  data_split$No$age, breaks = seq(20, 85, by = 5), col = "#F24B4B", border = "black",
  main = "Individus sains", xlab = "√Çge", ylab = "Effectif", xlim = c(20, 85)
)
```

#### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
ggplot2::ggplot(data = data_chdage, mapping = ggplot2::aes(x=age)) +
  ggplot2::geom_histogram(binwidth = 5 ,boundary = 20, color = "black", fill = "#F24B4B") +
  ggplot2::facet_grid(
    chd ~ .,
    labeller = ggplot2::labeller(chd=c("Yes"="Individus malades", "No"="Individus sains"))
  ) +
  ggplot2::labs(x = "√Çge", y = "Effectif") +
  ggplot2::theme_light()
```
:::

### Diagramme quantile-quantile

::: {.panel-tabset group="language"}
#### Base R

```{webr}
#| envir: baser
#| autorun: true
# Diviser les donn√©es par la variable `chd`
data_split <- split(data_chdage, data_chdage$chd)

# Configurer les facettes avec `par()`
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1)) # 2 lignes, 1 colonne

# QQ plot pour les individus malades ("Yes")
qqnorm(data_split$Yes$age, main = "Individus malades", xlab = "Quantiles th√©oriques",
       ylab = "Quantiles observ√©s", col = "black", pch = 16)
qqline(data_split$Yes$age, col = "#F24B4B", lwd = 2)

# QQ plot pour les individus sains ("No")
qqnorm(data_split$No$age, main = "Individus sains", xlab = "Quantiles th√©oriques",
       ylab = "Quantiles observ√©s", col = "black", pch = 16)
qqline(data_split$No$age, col = "#F24B4B", lwd = 2)
```

#### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
ggplot2::ggplot(data = data_chdage, mapping = ggplot2::aes(sample =age)) +
  ggplot2::stat_qq() +
  ggplot2::stat_qq_line(color = "#F24B4B") +
  ggplot2::facet_grid(
    chd ~ .,
    labeller = ggplot2::labeller(chd=c("Yes"="Individus malades", "No"="Individus sains"))
  ) +
  ggplot2::labs(x = "Quantiles th√©oriques", y = "Quantiles observ√©s") +
  ggplot2::theme_light()
```
:::
:::::

La normalit√© est sujette √† d√©bat, cependant, on peut dire qu'elle n'est
pas compl√®tement √©loign√©e, √©tant donn√© que les lois semblent √™tre en
grande partie unimodales et pas excessivement asym√©triques (bien que
l√©g√®rement asym√©triques tout de m√™me pour les individus malade). De
plus, l'√©galit√© des variances semble plausible au vu des boxplots.

:::

:::

## Question 4

On note $Y = \mathbb{1}_{\texttt{chd}=\texttt{Yes}}$  et $p(x) = \mathbb{P}(Y = 1|\texttt{age} = x)$. Donner la loi de $Y$ sachant que $\texttt{age}=x$ en fonction de $p(x)$.

::: {.content-visible when-meta="is_answer_print_4"}

::: answer

Le support de la variable al√©atoire $Y|(\texttt{age}=x)$ est $\{0, 1\}$
donc :

$$
Y|(\texttt{age}=x) \sim \mathcal{B}(p(x))
$$

:::

:::

## Question 5

En s‚Äôappuyant sur cette loi, donner la vraisemblance des observations $(y_1, \dots , y_n)$
en fonction de $\left(p(x_1), \dots , p(x_n)\right)$ o√π $x_i$ d√©signe l‚Äô√¢ge de l‚Äôindividu $i$ et 
$y_i = 1$ si ce dernier a une maladie coronarienne.

::: {.content-visible when-meta="is_answer_print_5"}

::: answer

Les variables al√©atoires
$\left(Y_i|(\texttt{age}=x)\right)_{i \in \{1, \dots, n\}}$ sont
ind√©pendantes de fonction de masse
$$\mathbb{P}(Y_i=y_i |\texttt{age}=x_i)=p(x_i)^{y_i}(1-p(x_i))^{1-y_i}$$

Ainsi, 

$$
\begin{align*}
L_n\left(p(x_1), \dots, p(x_n)\right)&=\prod\limits_{i=1}^n \mathbb{P}(Y_i=y_i | \texttt{age}=x_i) \\
&=\prod\limits_{i=1}^n p(x_i)^{y_i}(1-p(x_i))^{1-y_i}
\end{align*}
$$

:::

:::

## Question 6

En guise de premi√®re estimation de $p(x)$, on met en oeuvre la d√©marche suivante :

a. Utiliser les 8 groupes d‚Äô√¢ge propos√©s via la variable $\texttt{agegrp}$ du jeu de donn√©es,
ce qui forme 8 groupes d‚Äôindividus associ√©s √† ces classes. Calculer 
$\overline{x}_1, \dots , \overline{x}_8$ le milieu de chaque classe d‚Äô√¢ge.
b. Calculer les proportions de $\texttt{chd} = \texttt{Yes}$ dans chaque groupe, not√©es 
$\hat{p}_1, \dots , \hat{p}_8$  (on pourra utiliser les fonctions `table` et `prop.table`).

::: {.content-visible when-meta="is_answer_print_6"}

::: answer

Les milieux des 8 classes d'√¢ges sont :

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
classes_age <- data_chdage$agegrp |> levels()
bornes_classes <- strsplit(classes_age, split = "-")
borne_inf <- sapply(bornes_classes, FUN = function(x){sum(as.numeric(x[1]))})
borne_sup <- sapply(bornes_classes, FUN = function(x){sum(as.numeric(x[2]))})

milieu_classe <- sapply(bornes_classes, FUN = function(x){sum(as.numeric(x))/2})
data_milieu_classe <- data.frame(
  classe = classes_age,
  borne_inf = borne_inf,
  borne_sup = borne_sup,
  milieu = milieu_classe
)
data_milieu_classe
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
data_milieu_classe <- data_chdage |>
  dplyr::distinct(agegrp) |>
  dplyr::mutate(
    borne_inf = as.numeric(stringr::str_split_i(string = as.character(agegrp), pattern = "-", i = 1)),
    borne_sup = as.numeric(stringr::str_split_i(string = as.character(agegrp), pattern = "-", i = 2)),
    milieu = (borne_sup + borne_inf)/2
  ) |>
  dplyr::rename(classe = "agegrp")
data_milieu_classe
```
:::

On calcule les proportions de malade par classe d'√¢ge.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
data_prop <- table(data_chdage$agegrp[data_chdage$chd=="Yes"])/table(data_chdage$agegrp)
data_prop <- data.frame(
  classe = classes_age,
  proportion = as.numeric(data_prop[classes_age])
)
data_prop
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
data_prop <- data_chdage |>
  dplyr::group_by(agegrp) |>
  dplyr::summarise(n = dplyr::n(), .groups = "drop") |>
  dplyr::left_join(
    y = {
          data_chdage |>
            dplyr::filter(chd == "Yes") |>
            dplyr::group_by(agegrp) |>
            dplyr::summarise(n_malade = dplyr::n(), .groups = "drop")
    },
    by = dplyr::join_by(agegrp)
  ) |>
  dplyr::mutate(proportion = ifelse(is.na(n_malade),0, n_malade/n)) |>
  dplyr::rename(classe = "agegrp") |>
  dplyr::select(classe, proportion)
data_prop
```
:::

On peut fusionner les deux tables obtenues dans cette question.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
data_milieu_classe_prop <- data_milieu_classe |> merge(y = data_prop, by = "classe")
data_milieu_classe_prop
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
data_milieu_classe_prop <- data_milieu_classe |> dplyr::left_join(y = data_prop, by = dplyr::join_by(classe))
data_milieu_classe_prop
```
:::

:::

:::

## Question 7

Afin d‚Äôanalyser la qualit√© de l‚Äôestimation pr√©c√©dente, transformer la variable 
$\texttt{chd}$ en variable num√©rique prenant les deux valeurs 0 et 1, et 
repr√©senter sur un m√™me graphique le nuage de points de 
$\texttt{age}$ et $\texttt{chd}$ (recod√©) et les proportions estim√©es dans
chaque classe $(\overline{x}_k, \hat{p}_k)$ pour $k = 1, \dots , 8$.

Quelles vertus et quelles limites cette proc√©dure d‚Äôestimation a-t-elle ?

::: {.content-visible when-meta="is_answer_print_7"}

::: answer

Dans cette question et la pr√©c√©dente, on mod√©lise en fait la loi de
d'√™tre atteint par une maladie coronarienne conditionnellement √† la
classe d'√¢ge des individus (i.e. la variable al√©atoire
$Y|(\texttt{agegrp}=x)$).

Comme le d√©coupage propos√© dans l'exercice contient 8 classes d'√¢ge,
huit param√®tres interviennent dans cette mod√©lisation. De fa√ßon analogue
√† la question 4, on a donc :
$$\forall \ k \in \{1, \dots, 8\}, \quad Y|(\texttt{agegrp}=k) \sim \mathcal{B}(p_k) \qquad  \textrm{avec} \ p_k \in \ ]0, \ 1[$$
Si on estime ($p_1, \dots, p_8$), par la m√©thode du maximum de
vraisemblance, chaque param√®tre $p_k$ est estim√© par la fr√©quence
empirique calcul√©e √† la question 6.(b).

::: {.callout-note collapse="true"}
### Preuve

$$
\begin{align*}
L_n\left(p_1, \dots, p_8\right)&=\prod\limits_{i=1}^n P(Y_i=y_i | \texttt{agegrp}=x_i) \\
&=\prod\limits_{i=1}^n p_{x_i}^{y_i}(1-p_{x_i})^{1-y_i}
\end{align*}
$$ Comme $\left(p_1, \dots, p_8\right) \in \ ]0,1[^8$, cette quantit√©
est strictement positive, ainsi en appliquant la fonction logarithme de
part et d'autre de l'√©galit√©, on a :

$$
\begin{align*}
\ln L_n\left(p_1, \dots, p_8\right)&=\sum\limits_{i=1}^n y_i\ln(p_{x_i})+(1-y_i)\ln(1-p_{x_i}) \\
&=\sum_{k=1}^8\sum\limits_{\substack{i \in \{1, \dots, n\} \\ x_i =k}} y_i\ln(p_k)+(1-y_i)\ln(1-p_k)
\end{align*}
$$ On cherche √† maximiser la vraisemblance (cela revient √† maximiser la
log-vraisemblance car la fonction $x \mapsto \ln(x)$ est croissante).

[Condition du premier ordre]{.underline} :

D√©terminons les points critiques.
$$\nabla \ln L_n\left(\hat{p}_1 \dots, \hat{p}_8\right) = 0$$ Pour tout
$k \in \{1, \dots, n \}$,

$$
\begin{align*}
\frac{\partial \ln L_n}{\partial p_k} \left(\hat{p}_1, \dots, \hat{p}_8\right) &= 0 \\
\sum\limits_{\substack{i \in \{1, \dots, n\} \\ x_i =k}} \left[\frac{y_i}{\hat{p}_k}-\frac{1-y_i}{1-\hat{p}_k}\right] &= 0 \\
\sum\limits_{\substack{i \in \{1, \dots, n\} \\ x_i =k}} \frac{y_i-\hat{p}_k }{\hat{p}_k(1-\hat{p}_k)} &= 0
\end{align*}
$$

D'o√π $$
\hat{p}_k = \frac{\sum\limits_{\substack{i \in \{1, \dots, n\} \\ x_i =k}} y_i}{\sum\limits_{\substack{i \in \{1, \dots, n\} \\ x_i =k}} 1}
$$ $\hat{p}_k$ correspond √† la fr√©quence empirque d'individus malades
dans la classe $k$ calcul√©e √† la question 6.(b).

[Condition du second ordre]{.underline} :

On calcule les d√©riv√©es partielles d'ordre 2 :
$$\forall\ k \in \{1, \dots, 8\}, \frac{\partial^2 \ln L_n}{\partial p_k^2}\left(p_1, \dots, p_8\right)=-\sum\limits_{\substack{i \in \{1, \dots, n\} \\ x_i =k}} \frac{y_i}{p_k^2}+\frac{1-y_i}{(1-p_k)^2} $$
$$\forall\ (i,j) \in \{1, \dots, 8\}^2 \ \textrm{avec} \ i \neq j, \frac{\partial^2 \ln L_n}{\partial p_i\partial p_j}\left(p_1, \dots, p_8\right)=0 $$
La matrice hessienne $H$ de la fonction
$(p_1, \dots, p_8) \mapsto \ln L_n\left(p_1 \dots, p_8\right)$ est donc
diagonale. De plus comme l'expression
$-\sum\limits_{\substack{i \in \{1, \dots, n\} \\ x_i =k}} \frac{y_i}{p_k^2}+\frac{1-y_i}{(1-p_k)^2}$
est toujours strictement n√©gative,
$\forall \ \left(p_1, \dots, p_8\right) \in ]0, 1[^8, H\left(p_1, \dots, p_8\right)$
est strictement d√©finie n√©gative donc la fonction
$(p_1, \dots, p_8) \mapsto \ln L_n\left(p_1 \dots, p_8\right)$ est
concave.

**Ainsi, le point critique** $\left(\hat{p}_1, \dots, \hat{p}_8\right)$
est l'unique point de maximum global dans $]0, \ 1[^8$.
:::

Le graphique demand√© est proche d'un de ceux r√©alis√©s pour la deuxi√®me
question avec les classes d'√¢ge.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
plot(
  data_chdage$age, as.numeric(data_chdage$chd)-1, 
  xlab = "√Çge", 
  ylab = "Valeur observ√©e ou probabilit√© pr√©dite", 
  pch = 19, 
  col = "black", 
  ylim = c(-0.2, 1.2) # Ajustement des limites pour inclure les segments
)
grid()

# Ajouter les segments horizontaux
segments(
  x0 = data_milieu_classe_prop$borne_inf, 
  x1 = data_milieu_classe_prop$borne_sup, 
  y0 = data_milieu_classe_prop$proportion, 
  y1 = data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  lwd = 1.2
)

# Ajouter les points aux bornes inf√©rieures
points(
  data_milieu_classe_prop$borne_inf, data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  pch = 19, 
  cex = 1.5
)

# Ajouter les points aux bornes sup√©rieures (vides √† l'int√©rieur)
points(
  data_milieu_classe_prop$borne_sup, data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  pch = 21, 
  bg = "white", 
  cex = 1.5
)

# L√©gende
legend(
  "bottom", 
  legend = c("Valeur observ√©e", "Probabilit√© pr√©dite"), 
  pch = c(19, NA), 
  lty = c(NA, 1), 
  col = c("black", "#F24B4B"), 
  pt.bg = c(NA, "white"), 
  horiz = TRUE, 
  bty = "n"
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
graphique_q7 <-
  ggplot2::ggplot() +
   ggplot2::geom_point(
    mapping =  ggplot2::aes(x=age, y=as.numeric(chd)-1L, shape="obs"),
    data = data_chdage
  ) +
   ggplot2::geom_segment(
    data = data_milieu_classe_prop,
    mapping = aes(
      x = borne_inf,
      xend=borne_sup,
      y=proportion,
      yend=proportion,
      lty="p_hat_q7",
      color="p_hat_q7"
    ),
    lineend  = "square",
    linewidth = 1.2
  ) +
   ggplot2::geom_point(
    data = data_milieu_classe_prop,
    mapping = aes(x=borne_inf,y=proportion),
    color= "#F24B4B",
    size=2
  ) +
   ggplot2::geom_point(
    data = data_milieu_classe_prop,
    mapping = aes(x=borne_sup, y=proportion),
    color= "#F24B4B",
    size=2,
    shape=21,
    fill='white'
  ) +
  ggplot2::labs(x="√Çge" , y="Valeur observ√©e ou probabilit√© pr√©dite") +
  ggplot2::scale_shape_manual("obs", values=c("obs"=19), labels=c("obs"="Valeur observ√©e"), name = "") +
  ggplot2::scale_linetype_manual(values=c("p_hat_q7"=1), name="", labels= c("p_hat_q7"="Probabilit√© pr√©dite")) +
  ggplot2::scale_color_manual(values=c("p_hat_q7"="#F24B4B"), name="", labels= c("p_hat_q7"="Probabilit√© pr√©dite")) +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "bottom")

graphique_q7

```
:::

**Points positifs de cette estimation :**

-   Cette estimation est simple √† r√©aliser car elle ne requiert qu'un
    calcul des fr√©quences empiriques.
-   L'hypoth√®se du mod√®le est simple √† formuler : tous les individus
    d'un classe d'√¢ge ont la m√™me probabilit√© d'√™tre malade.

**Points n√©gatifs de cette estimation :**

-   La contrepartie de cette hypoth√®se simple est qu'elle produit une
    estimation peu r√©aliste en raison de la discontinuit√© syst√©matique
    lors d'une passage d'une classe d'√¢ge √† la suivante et l'homog√©n√©it√©
    impos√©e au sein de chaque classe d'√¢ge. L'estimation est donc assez
    grossi√®re.
-   Le mod√®le est peu parcimonieux car il fait intervenir 8 param√®tres
    pour 100 observations.
-   Ce type de mod√®le se g√©n√©ralise mal au cas o√π l'on souhaite faire
    intervenir plus d'une variable explicative continue. Le nombre de
    groupe d'individus issus des croisements des variables discr√©tis√©es
    explose rapidement. L'estimation devient alors peu robuste car
    certains regroupements risquent de rassembler peu d'individus. Par
    ailleurs, il devient difficile d'isoler les effets marginaux d'une
    variable explicative sur la variable √† expliquer et donc
    d'interpr√©ter les r√©sultats.

:::

:::

## Question 8

On d√©cide de mod√©liser $p(x)$ √† l‚Äôaide d‚Äôun mod√®le de r√©gression logistique de
param√®tre $\beta = (\beta_0, \beta_1) \in \mathbb{R}^2$ 

Quelle hypoth√®se cela signifie-t-il sur l‚Äôexpression de $p(x)$ ? 

Cela est-il compatible avec le graphique pr√©c√©dent ? 

Quelle(s) autre(s) alternative(s) de mod√©lisation pourrait-on sugg√©rer ?

::: {.content-visible when-meta="is_answer_print_8"}

::: answer

Le mod√®le logistique s'√©crit :

$$Y|(\mathtt{age}=x) \sim \mathcal{B}(p(x))$$ avec
$$ \textrm{logit}(p(x))= \beta_0+\beta_1x \quad \textrm{o√π} \ \textrm{logit}: p \longmapsto \ln\left(\frac{p}{1-p} \right)$$
Ce mod√®le fait intervenir deux pam√®tres : une constante et un
coefficient associ√© √† l'√¢ge de l'individu.

Pour d√©terminer l'hypoth√®se sur l'expression de $p(x)$, il suffit
d'inverser la fonction $\textrm{logit}$ (qui est strictement croissante
et continue sur $]0,1[$ donc est une bijection de $]0,1[$ vers
$\mathbb{R}$).

$$
\begin{align*}
\textrm{logit}(p(x))= \beta_0+\beta_1x &\Longleftrightarrow  \ln\left(\frac{p(x)}{1-p(x)} \right) = \beta_0+\beta_1x \\
&\Longleftrightarrow \frac{p(x)}{1-p(x)} = \exp(\beta_0+\beta_1x) \\
&\Longleftrightarrow  p(x) =\exp(\beta_0+\beta_1x) (1-p(x)) \\
&\Longleftrightarrow  p(x)(1+\exp(\beta_0+\beta_1x)) =\exp(\beta_0+\beta_1x) \\
&\Longleftrightarrow  p(x) = \frac{\exp(\beta_0+\beta_1x)}{1+\exp(\beta_0+\beta_1x)} \\
\end{align*}
$$

Cette expression de $p(x)$ conduit √† une courbe en S (c'est une
sigmo√Øde). Elle est partiellement compatible avec le graphique pr√©c√©dent
si $\beta_1>0$. En effet, dans les deux cas, la probabilit√© estim√©e est
croissante avec $x$ (i.e. l'√¢ge) et elles tendent vers $0$ lorsque
$x \to -\infty$ et vers $1$ lorsque $x \to + \infty$. N√©anmoins elles
diff√®rent notamment car il n'y a plus les effets de seuil comme √† la
question 7.

```{ojs}
//| echo: false

viewof a = Inputs.range([-10, 10], { value: -5.309, step: 0.001, label: tex`\beta_0:`}) ;
viewof b = Inputs.range([-1, 1], { value: 0.111, step: 0.001, label: tex`\beta_1:`}) ;

arrayRange = (start, stop, step) =>
    Array.from(
    { length: (stop - start) / step + 1 },
    (value, index) => start + index * step
);
    
{
  // The function that we are sampling is sin(a * x), where the symbol a
  // refers to the valu of the slider below.
  let x_value = arrayRange(2000,7000,1).map(x => x/100) ;
  let samples = x_value.map((x) => [x, Math.exp((a +b*x))/(1+Math.exp((a +b*x)))]);
  let w = 900;
  let h = 0.5 * w;
  let plot = Plot.plot({
    y: { domain: [0, 1] },
    width: w,
    height: h,
    marks: [
      Plot.line([[20,0.1],[30,0.1]],{
        strokeWidth: 2,
        stroke: "#F24B4B",
        markerStart: "dot",
        markerEnd: "circle-stroke"
      }),
      Plot.line([[30,0.133],[35,0.133]],{
        strokeWidth: 2,
        stroke: "#F24B4B",
        markerStart: "dot",
        markerEnd: "circle-stroke"
      }),
      Plot.line([[35,0.25],[40,0.25]],{
        strokeWidth: 2,
        stroke: "#F24B4B",
        markerStart: "dot",
        markerEnd: "circle-stroke"
      }),
      Plot.line([[40,0.333],[45,0.333]],{
        strokeWidth: 2,
        stroke: "#F24B4B",
        markerStart: "dot",
        markerEnd: "circle-stroke"
      }),
      Plot.line([[45,0.462],[50,0.462]],{
        strokeWidth: 2,
        stroke: "#F24B4B",
        markerStart: "dot",
        markerEnd: "circle-stroke"
      }),
      Plot.line([[50,0.625],[55,0.625]],{
        strokeWidth: 2,
        stroke: "#F24B4B",
        markerStart: "dot",
        markerEnd: "circle-stroke"
      }),
      Plot.line([[55,0.765],[60,0.765]],{
        strokeWidth: 2,
        stroke: "#F24B4B",
        markerStart: "dot",
        markerEnd: "circle-stroke"
      }),
      Plot.line([[60,0.8],[70,0.8]],{
        strokeWidth: 2,
        stroke: "#F24B4B",
        markerStart: "dot",
        markerEnd: "circle-stroke"
      }),
      Plot.line(samples, {
        strokeWidth: 3,
        stroke: "steelblue",
      }),
      Plot.ruleX([20]),
      Plot.ruleY([0])
    ]
  });

  return plot;
}
```

D'autres fonctions en forme de ¬´S¬ª √† valeur dans $\mathbb{R}$ vers
$]0,1[$ auraient pu √™tre appropri√©es, notamment des fonctions de
r√©partition telles que la fonction de r√©partition d'une loi Gaussienne
standard (mod√®le probit) ou la fonction de r√©partition d'une loi de
Gumbel standard (mod√®le log-log compl√©mentaire), qui sont parmi les plus
couramment utilis√©es.

Il peut √™tre utile de d√©finrir en {{< iconify logos:r-lang >}}, les deux fonctions vectorielles
suivantes :

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
logit <- function(x){log(x/(1-x))}
logit_inv <- function(x){exp(x)/(1+exp(x))}
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
logit <- function(x){log(x/(1-x))}
logit_inv <- function(x){exp(x)/(1+exp(x))}
```
:::

:::

:::

## Question 9

Ecrire la log-vraisemblance du mod√®le logistique en fonction de $\beta$ et en d√©duire le
syst√®me que doit r√©soudre le maximum de vraisemblance $\hat{\beta}$.

Peut-on r√©soudre ce syst√®me analytiquement ?

::: {.content-visible when-meta="is_answer_print_9"}

::: answer

On injecte l'expression de $p(x)$ pour le mod√®le logistique dans
l'expression de la vraisemblance "g√©n√©rale" pour des variables
al√©atoires suivant des lois de Bernoulli d√©termin√©e √† la question 5.

$$
\begin{align*}
L_n\left(\beta_0, \beta_1\right)
&=\prod\limits_{i=1}^n p(x_i)^{y_i}(1-p(x_i))^{1-y_i} \\
&= \prod\limits_{i=1}^n\left(\frac{\exp(\beta_0+\beta_1x_i)}{1+\exp(\beta_0+\beta_1x_i)}\right)^{y_i}\left(1-\frac{\exp(\beta_0+\beta_1x_i)}{1+\exp(\beta_0+\beta_1x_i)}\right)^{1-y_i} \\
&=\prod\limits_{i=1}^n\left(\frac{\exp(\beta_0+\beta_1x_i)}{1+\exp(\beta_0+\beta_1x_i)}\right)^{y_i}\left(\frac{1}{1+\exp(\beta_0+\beta_1x_i)}\right)^{1-y_i}
\end{align*}
$$

En appliquant la fonction $\ln$ de part et d'autre de l'√©galit√©,

$$
\begin{align*}
\ln L_n\left(\beta_0, \beta_1\right)&=\sum\limits_{i=1}^n \left[ y_i\ln\left(\frac{\exp(\beta_0+\beta_1x_i)}{1+\exp(\beta_0+\beta_1x_i)}\right)+(1-y_i)\ln\left(\frac{1}{1+\exp(\beta_0+\beta_1x_i)}\right)\right] \\
&=\sum\limits_{i=1}^n \left[ y_i(\beta_0+\beta_1x_i)-y_i\ln\left(1+\exp(\beta_0+\beta_1x_i)\right)-(1-y_i)\ln\left(1+\exp(\beta_0+\beta_1x_i)\right)\right] \\
&=\sum\limits_{i=1}^n \left[ y_i(\beta_0+\beta_1x_i)-\ln\left(1+\exp(\beta_0+\beta_1x_i)\right) \right]
\end{align*}
$$

On cherche un point critique $(\widehat{\beta_0}, \widehat{\beta_1})$ de
cette fonction de la log-vraisemblance c'est √† dire tel que
$\nabla \ln L_n\left(\widehat{\beta_0}, \widehat{\beta_1}\right)=0$.

$$
\nabla \ln L_n\left(\widehat{\beta_0}, \widehat{\beta_1}\right) =
\begin{pmatrix}
\frac{\partial \ln L_n}{\partial \beta_0}\left(\widehat{\beta_0}, \widehat{\beta_1}\right) \\
\frac{\partial \ln L_n}{\partial \beta_1}\left(\widehat{\beta_0}, \widehat{\beta_1}\right) 
\end{pmatrix} = 
\begin{pmatrix}
\sum\limits_{i=1}^n  \left[y_i-\frac{\exp(\widehat{\beta_0}+\widehat{\beta_1}x_i)}{1+\exp(\widehat{\beta_0}+\widehat{\beta_1}x_i)}\right] \\
\sum\limits_{i=1}^n  \left[y_i-\frac{\exp(\widehat{\beta_0}+\widehat{\beta_1}x_i)}{1+\exp(\widehat{\beta_0}+\widehat{\beta_1}x_i)}\right]x_i
\end{pmatrix}
=
\begin{pmatrix}
0 \\
0
\end{pmatrix}
$$

On ne peut pas d√©terminer une solution analytique de l'estimateur du
maximum de vraisemblance
$\hat{\boldsymbol{\beta}}=\left(\widehat{\beta_0}, \widehat{\beta_1}\right)$
car les √©quations ne sont pas lin√©aires en $\boldsymbol{\beta}$.

On va rechercher des solutions approch√©es num√©riquement dans la question
suivante.

:::

:::

## Question 10

Calculer l‚Äôestimateur du maximum de vraisemblance via la fonction `glm`.

::: {.content-visible when-meta="is_answer_print_10"}


::: answer

On peut utiliser la fonction `glm` de {{< iconify logos:r-lang >}} pour l'approximation num√©rique.
C'est ce qu'on doit faire en pratique. Les arguments sont semblables √†
la fonction `lm`. Il faut faire attention √† bien param√©trer l'argument
`family` sans quoi on estimerait un mod√®le de r√©gression lin√©aire
simple.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
?family
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
?family
```
:::

On doit prendre ici `family=binomial()` car $Y$ sachant $X$ suit une loi
de Bernoulli.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
modele_logit <- glm(
  (as.integer(chd)-1L) ~ age,
  family = binomial(link="logit"),
  data = data_chdage
)
summary(modele_logit)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
modele_logit <- glm(
  (as.integer(chd)-1L) ~ age,
  family = binomial(link="logit"),
  data = data_chdage
)
summary(modele_logit)
```
:::

On peut lire l'estimation par maximum de vraissemblance :
$\widehat{\beta_0} = -5,30945$ et $\widehat{\beta_1} = 0,11092$.

:::

:::

## Question 11

Rappeler la d√©finition th√©orique du rapport de cotes (odds ratio) d‚Äôavoir une maladie
coronarienne entre un individu d‚Äô√¢ge $x_1$ et un individu d‚Äô√¢ge $x_2$. Que vaut-il pour le
mod√®le pr√©c√©dent lorsque les 2 individus ont 10 ans d‚Äô√©cart (c‚Äôest √† dire $x_1 = x_2+10$) ?

::: {.content-visible when-meta="is_answer_print_11"}

::: answer

La cote (l'odds) pour un individu avec des caract√©ristiques $x$ est le
ratio entre la probabilit√© que l'√©v√©nement (ici avoir un maladie
coronarienne) se produise et la probabilit√© qu'il ne se produise pas.

$$\textrm{odds}(x)=\frac{p(x)}{1-p(x)}$$

L'odds-ratio (OR) d'avoir une maladie coronarienne entre un individu
d'√¢ge $x_1$ et un autre individu d'√¢ge $x_2$ est le rapport :

$$OR(x_1, x_2) = \frac{\textrm{odds}(x_1)}{\textrm{odds}(x_2)} = \frac{\frac{p(x_1)}{1-p(x_1)}}{\frac{p(x_2)}{1-p(x_2)}}$$

Dans le cadre du mod√®le logistique,

$$\textrm{odds(x)}=\exp(\beta_0+\beta_1x)$$ Donc

$$OR(x_1, x_2) = \frac{\exp(\beta_0+\beta_1x_1)}{\exp(\beta_0+\beta_1x_2)} = \exp(\beta_1(x_1-x_2))$$

Pour des individus qui ont 10 ans d'√©cart, on trouve :

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
exp(10*modele_logit$coefficients[2])
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
exp(10*modele_logit$coefficients[2])
```
:::

On peut donc affirmer que la cote de survenue de la maladie coronarienne
est environ multipli√©e par 3 tous les 10 ans toutes choses √©gales par
ailleurs.

:::

:::

## Question 12

On s‚Äôint√©resse √† pr√©sent au rapport de probabilit√©s (et non de cotes) d‚Äôavoir une
maladie coronarienne entre un individu d‚Äô√¢ge $x_1$ et un individu d‚Äô√¢ge $x_2$. Que vaut
ce rapport pour le mod√®le pr√©c√©dent lorsque les 2 individus ont 10 ans d‚Äô√©cart (c‚Äôest
√† dire $x_1 = x_2 + 10$) ? On pourra repr√©senter ce rapport en fonction de $x_2$, pour $x_2$ prenant des valeurs de 20 √† 70 ans.

::: {.content-visible when-meta="is_answer_print_12"}

::: answer

D'apr√®s la question 6, pour le mod√®le logistique, on a

$$
p(x) = \frac{\exp(\beta_0+\beta_1x)}{1+\exp(\beta_0+\beta_1x)}=\frac{1}{1+\exp(-(\beta_0+\beta_1x))}
$$ Le rapport de probabilit√© vaut

$$
\frac{p(x_2+10)}{p(x_2)} = \frac{1+\exp(-(\beta_0+\beta_1x_2))}{1+\exp(-(\beta_0+\beta_1(x_2+10))}
$$

Contrairement au rapport de cote, le rapport de probabilit√© d√©pend de
l'√¢ge $x_2$.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
vecteur_ages <- seq(from = 20 , to = 70, by = 0.1)
beta_0 <- coef(modele_logit)[1]
beta_1 <- coef(modele_logit)[2]
plot(
  x = vecteur_ages,
  y = (1+exp(-beta_0-beta_1*vecteur_ages))/(1+exp(-beta_0-beta_1*(vecteur_ages+10))),
  xlab = "√Çge",
  ylab = "Rapport de probabilit√©s"
)
grid()
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
vecteur_ages <- seq(from = 20 , to = 70, by = 0.1)
beta_0 <- coef(modele_logit)[1]
beta_1 <- coef(modele_logit)[2]

# Calcul du rapport de probabilit√©s pour chaque √¢ge
data_ages <- data.frame(
  age = vecteur_ages,
  rapport_probabilites = (1 + exp(-beta_0 - beta_1 * vecteur_ages)) / 
                         (1 + exp(-beta_0 - beta_1 * (vecteur_ages + 10)))
)

# Tracer le graphique avec ggplot2
ggplot2::ggplot(
  data = data_ages,
  mapping = ggplot2::aes(x = age, y = rapport_probabilites)
) +
  ggplot2::geom_line(color = "blue", linewidth = 1) +  # Ajouter la courbe
  ggplot2::labs(
    x = "√Çge", 
    y = "Rapport de probabilit√©s"
  ) +
  ggplot2::theme_light()
```
:::

:::

:::


## Question 13

On rappelle que sous "de bonnes conditions", l‚Äôestimateur du maximum de vraisemblance $\beta$ dans un mod√®le de r√©gression logistique portant sur $p$ variables explicatives et 
$n$ individus v√©rifie la convergence en loi suivante, lorsque $n \to \infty$,

$$
J_n(\beta)^{1/2}\left(\hat{\beta}-\beta\right) \overset{\mathcal{L}}{\longrightarrow} \mathcal{N}\left(0_p, I_p\right)
$$

o√π $J_n(\beta)$ est la matrice d‚Äôinformation de Fisher. Cette derni√®re admet l‚Äôexpression

$$
J_n(\beta)=\boldsymbol{X}^{'}W_{\beta}\boldsymbol{X}
$$

o√π $\boldsymbol{X}$ est la matrice de design et $W_{\beta}$ est la matrice diagonale

$$
W_{\beta} =
\begin{pmatrix}
p_{\beta}(x_1)\left(1-p_{\beta}(x_1)\right) & & 0 \\
 & \ddots & \\
0 &      &  p_{\beta}(x_n)\left(1-p_{\beta}(x_n)\right) 
\end{pmatrix}
$$


Justifier qu‚Äôune approximation asymptotique de la loi de $(\hat{\beta}-\beta)$ est $\mathcal{N}\left(0_p, J_n^{-1}(\beta)\right)$

::: {.content-visible when-meta="is_answer_print_13"}

::: answer

D'apr√®s la convergence en loi rappel√©e dans l'√©nonc√©, on a
approximatovement :
$$J_n(\beta)^{1/2}(\boldsymbol{\hat{\beta}}-\boldsymbol{\beta}) \approx \mathcal{N}(0_2, I_2)$$

En multipliant par $J_n(\beta)^{-1/2}$ √† gauche, on a :
$$\boldsymbol{\hat{\beta}}-\boldsymbol{\beta} \approx \mathcal{N}(0_2, J_n(\beta)^{-1})$$

:::

:::

## Question 14

Comment peut-on exploiter ce r√©sultat pour estimer l‚Äô√©cart-type de chaque coordonn√©e de $\hat{\beta}$ ? On donnera la d√©marche concr√®te √† appliquer, mais on ne demande pas
de la mettre en pratique num√©riquement.

::: {.content-visible when-meta="is_answer_print_14"}

::: answer

-   On estime la matrice $J_n(\beta)$ par
    $J_n(\widehat{\beta})=\boldsymbol{X}'W_{\widehat{\beta}}\boldsymbol{X}$.
    Pour cela, on remplace les $p_\beta(x_i)$ dans $W_\beta$ par
    $p_{\widehat{\beta}}(x_i)=\frac{e^{\widehat{\beta}'x_i}}{1+e^{\widehat{\beta}'x_i}}$

-   On calcule l'inverse de $J_n(\widehat{\beta})$ qui correspond √† une
    estimation de la matrice de variance covariance de asymptotique de
    $\widehat{\beta}$.

-   L'√©l√©ment diagonal num√©ro $j$ de cette derni√®re matrice correspond
    donc √† une estimation de la variance asymptotique de la coordonn√©e
    $\widehat{\beta}_j$ . Sa racine carr√©e constitue ainsi une
    estimation de l'√©cart-type de $\widehat{\beta}_j$.

:::

:::

## Question 15

Cette proc√©dure d‚Äôestimation est utilis√©e par la fonction `glm`. 
En utilisant sa sortie, donner une estimation de l‚Äô√©cart-type de 
$\hat{\beta}_0$ et $\hat{\beta}_1$.

::: {.content-visible when-meta="is_answer_print_15"}

::: answer
Il s'agit de la deuxi√®me colonne dans la sortie de `summary`. Cela nous
donne un √©cart type estim√© de 1,13365 pour $\widehat{\beta}_0$ et de
0,02406 pour $\widehat{\beta}_1$.
:::

:::

## Question 16

Construire un intervalle de confiance asymptotique √† 95 % pour le param√®tre $\beta_1$.

::: {.content-visible when-meta="is_answer_print_16"}

::: answer

L'intervalle de confiance asymptotique au niveau de confiance
$1 ‚àí \alpha$ pour $\hat{\beta_1}$ est donn√©e par :
$$\left[\hat{\beta}_1 - q_{1-\alpha/2}^{\mathcal{N}(0,1)}\hat{\sigma}_1 \ ; \ \hat{\beta}_1 + q_{1-\alpha/2}^{\mathcal{N}(0,1)}\hat{\sigma}_1 \right]$$

Cela donne num√©riquement :

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
alpha <- 0.05
beta_mle_1 <- modele_logit$coefficients[2]
sigma_est_1 <- sqrt(vcov(modele_logit)[2,2])
quantile_alpha <- qnorm(mean = 0, sd = 1, p = 1-alpha/2) 

paste0(
  "[",
  beta_mle_1-quantile_alpha*sigma_est_1,
  " ; ",
  beta_mle_1+quantile_alpha*sigma_est_1,
  "]"
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
alpha <- 0.05
beta_mle_1 <- modele_logit$coefficients[2]
sigma_est_1 <- sqrt(vcov(modele_logit)[2,2])
quantile_alpha <- qnorm(mean = 0, sd = 1, p = 1-alpha/2) 

paste0(
  "[",
  beta_mle_1-quantile_alpha*sigma_est_1,
  " ; ",
  beta_mle_1+quantile_alpha*sigma_est_1,
  "]"
)
```
:::

Ou plus simplement en {{< iconify logos:r-lang >}},

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
confint.default(modele_logit, parm = "age")
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
confint.default(modele_logit, parm = "age")
```
:::

:::

:::

## Question 17

D‚Äôapr√®s la question pr√©c√©dente, le param√®tre $\beta_1$ est-il diff√©rent de 0 
au seuil d‚Äôerreur asymptotique 5 % ?
Quel est le nom de cette proc√©dure de test. 
Donner la $\textit{p-value}$ associ√©e √† ce test et v√©rifier qu‚Äôelle concorde bien avec la sortie de `glm`.

::: {.content-visible when-meta="is_answer_print_17"}

::: answer

Comme $0$ n'appartient pas √† l'intervalle de confiance pr√©c√©dent,
$\beta_1$ est diff√©rent de $0$ au seuil d'erreur asymptotique 5 %.

Le test qui consiste √† regarder si un param√®tre est nul en s'appuyant
sur la normalit√© asymptotique de son estimateur est connue sous le nom
de "test de Wald".

La p-valeur vaut
$$2\left(1-F_{\mathcal{N(0,1)}}(T)\right) \quad \textrm{avec} \ T=\frac{\widehat{\beta_1}}{\widehat{\sigma_1}}$$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
2*(1-pnorm(beta_mle_1/sigma_est_1, mean = 0, sd = 1))
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
2*(1-pnorm(beta_mle_1/sigma_est_1, mean = 0, sd = 1))
```
:::

Num√©riquement on obtient $\textit{p-valeur} = 4,022426\times10^{-06}$.
C'est la m√™me valeur que dans la sortie de la fonction `glm`.

:::

:::

## Question 18

Calculer la statistique du test de d√©viance de significativit√© du mod√®le GLM (par
rapport au mod√®le nul). En d√©duire la p-value et conclure aux seuils d‚Äôerreur 10 %,
5 % et 1 %. Comparer avec les r√©sultats du test effectu√© sous {{< iconify logos:r-lang >}} √† l‚Äôaide de la fonction
`anova` appliqu√© au mod√®le, avec l‚Äôoption `test="Chisq"`.

::: {.callout-note collapse="true"}
#### Fonction de r√©partition et quantiles pour des lois du chi-2 sous R

Pour une loi du chi-2 √† $d$ degr√©s de libert√©, l'image de la fonction de
r√©partition de la loi $\mathcal{\chi}^2(d)$ en $x$ est calculable sous {{< iconify logos:r-lang >}}
avec la fonction `pchisq`.
$F_{\mathcal{\chi}^2(d)}(x) =\mathbb{P}\left(\mathcal{\chi}^2(d) < x\right)$
s'obtient avec l'expression :

```         
pchisq(q = x, df = d)
```

Pour cette m√™me loi $\mathcal{\chi}^2(d)$, le quantile
$q_{\alpha}^{\mathcal{\chi}^2(d)}$ avec $\alpha \in ]0, 1[$ tel que
$F_{\mathcal{\chi}^2(d)}\left(q_{\alpha}^{\mathcal{\chi}^2(d)}\right)= \alpha$
est calculable sous {{< iconify logos:r-lang >}} gr√¢ce √† la fonction `qchisq` via l'expression

```         
qchisq(p = alpha, df = d)
```
:::

::: {.content-visible when-meta="is_answer_print_18"}

::: answer

On veut tester la significativit√© globale du mod√®le avec un test du
rapport de vraisemblance. On veut v√©rifier ou non qu'au moins une des
variables du mod√®le explique l'√©v√®nement d'int√©r√™t. Ici, on a qu'un
param√®tre dans le mod√®le en dehors de la constante donc on veut tester :

$$H_0: \beta_1 = 0 $$ contre $$H_1: \beta_1 \neq 0 $$

Sous $H_0$, on a :

$$2\left( \ln L \left(\hat{\beta}\right) -  \ln L \left(\hat{\beta}_{H_0}\right) \right) \overset{\mathcal{L}}{\longrightarrow} \chi^2(1)$$
Le nombre de degr√©s de libert√© correspond √† la diff√©rence de param√®tres
entre les deux mod√®les : ici c'est 1.

Pour $n$ suffisamment grand, on rejette $H_0$ au seuil $\alpha$ si

$$2\left( \ln L \left(\hat{\beta}\right) -  \ln L \left(\hat{\beta}_{H_0}\right) \right) > q_{1-\alpha}^{\chi^2(1)}$$

Cette statistique s'exprime en fonction des d√©viances du mod√®le nul
$D_{H_0}$ et la d√©viance du mod√®le estim√© $D_{H_1}$. En effet, la
d√©fiance $D$ d'un mod√®le (logistque ou autre) vaut :

$$D = 2(\ln(L_{sat})-\ln(L_{mod}))$$

La statistique de test $D_{H_0}-D_{H_1}$ vaut

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
stat_test_deviance <- summary(modele_logit)$null.deviance-summary(modele_logit)$deviance
stat_test_deviance
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
stat_test_deviance <- summary(modele_logit)$null.deviance-summary(modele_logit)$deviance
stat_test_deviance
```
:::

√† comparer avec

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
qchisq(p = c(0.9, 0.95, 0.99), df = 1)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
qchisq(p = c(0.9, 0.95, 0.99), df = 1)
```
:::

On rejette donc l'hypoth√®se nulle aux seuils 10 %, 5 % et 1 %.

La p-valeur vaut $1-F_{\chi^2(1)}(T)$ o√π $T$ est la statistique
de test.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
1-pchisq(stat_test_deviance, df=1)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
1-pchisq(stat_test_deviance, df=1)
```
:::

On retrouve la m√™me p-valeur avec la foncion `anova`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
anova(modele_logit, test = "Chisq")
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
anova(modele_logit, test = "Chisq")
```
:::

:::

:::

## Question 19

Reprendre le graphique effectu√© √† la question 7 et superposer (sous forme d‚Äôune
courbe) les valeurs pr√©dites $\hat{p}(x)$ par le mod√®le logistique, calcul√©es pour une grille de valeurs de $x$ couvrant l‚Äô√©tendue prise par les observations. On pourra utiliser la fonction `predict` associ√©e √† l‚Äôoption `type="response"`.

::: {.content-visible when-meta="is_answer_print_19"}

::: answer

On ajoute les valeurs pr√©dites par le mod√®le logistique.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
#| fig-width: 9
# Valeurs observ√©es
plot(
  data_chdage$age, as.numeric(data_chdage$chd)-1, 
  xlab = "√Çge", 
  ylab = "Valeur observ√©e ou probabilit√© pr√©dite", 
  pch = 19, 
  col = "black", 
  ylim = c(-0.2, 1.2) # Ajustement des limites pour inclure les segments
)
grid()

# Ajouter les segments horizontaux des valeurs pr√©dites Q7
segments(
  x0 = data_milieu_classe_prop$borne_inf, 
  x1 = data_milieu_classe_prop$borne_sup, 
  y0 = data_milieu_classe_prop$proportion, 
  y1 = data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  lwd = 1.2
)

# Ajouter les points aux bornes inf√©rieures
points(
  data_milieu_classe_prop$borne_inf, data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  pch = 19, 
  cex = 1.5
)

# Ajouter les points aux bornes sup√©rieures (vides √† l'int√©rieur)
points(
  data_milieu_classe_prop$borne_sup, data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  pch = 21, 
  bg = "white", 
  cex = 1.5
)

# Ajout des pr√©dictions de la Q8
fake_data <- data.frame(age = seq(from = 20, to = 70, by = 0.1))
fake_data$p_hat <- predict(modele_logit, newdata=fake_data, type = "response")

lines(
  x = fake_data$age,
  y = fake_data$p_hat,
  col = "#3854A6", 
  lwd = 1.2
)

# L√©gende
legend(
  "bottom", 
  legend = c("Valeur observ√©e", "Probabilit√© pr√©dite (Q7)", "Probabilit√© pr√©dite (Q8)"), 
  pch = c(19, NA, NA), 
  lty = c(NA, 1, 1), 
  col = c("black", "#F24B4B", "#3854A6"), 
  pt.bg = c(NA, "white", "white"), 
  horiz = TRUE, 
  bty = "n"
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
#| fig-width: 8
fake_data <- data.frame(age = seq(from = 20, to = 70, by = 0.1))
fake_data$p_hat <- predict(modele_logit, newdata=fake_data, type = "response")


graphique_q19 <- graphique_q7 +
  ggplot2::geom_line(
    data = fake_data,
    mapping = ggplot2::aes(x = age, y=p_hat, lty="p_hat_q8", color="p_hat_q8"),
    linewidth = 1.2
  ) + 
  ggplot2::scale_linetype_manual(values=c("p_hat_q7"=1, "p_hat_q8"=1), name="", labels= c("p_hat_q7"="Probabilit√© pr√©dite (mod√®le Q7)", "p_hat_q8"="Probabilit√© pr√©dite (mod√®le Q8)")) +
  ggplot2::scale_color_manual(values=c("p_hat_q7"="#F24B4B", "p_hat_q8"="#3854A6"), name="", labels= c("p_hat_q7"="Probabilit√© pr√©dite (mod√®le Q7)", "p_hat_q8"="Probabilit√© pr√©dite (mod√®le Q8)")) +
  ggplot2::theme_light() +
  ggplot2::theme(legend.position = "bottom")
graphique_q19
```
:::

:::

:::

## Question 20

En partant de la convergence en loi de $\hat{\beta}$ rappel√©e ci-dessus, en d√©duire un intervalle de confiance au niveau asymptotique 95 % pour $p(x)$.
Ajouter cet intervalle de confiance pour chaque $x$ consid√©r√© au graphique pr√©c√©dent.
On pourra exploiter avec profit l‚Äôoption `se=TRUE` de la fonction `predict` dans le cas `type="link"`.

::: {.content-visible when-meta="is_answer_print_20"}

::: answer

On note

$$
\boldsymbol{V}(\boldsymbol{\beta})^{-1}=(\mathbb{X}'\boldsymbol{W}(\boldsymbol{\beta})\mathbb{X})^{-1}=\begin{pmatrix}
\sigma_0^2 & \gamma \\ \gamma & \sigma_{1}^2
\end{pmatrix}
$$

Asymptotiquement,

$$
\begin{align*}
\boldsymbol{V}(\boldsymbol{\beta})^{1/2}(\hat{\boldsymbol{\beta}}-\boldsymbol{\beta}) \approx \mathcal{N}(0, I_2)
&\Longrightarrow \hat{\boldsymbol{\beta}}-\boldsymbol{\beta} \approx \mathcal{N}(0, \boldsymbol{V}(\boldsymbol{\beta})^{-1}) \\
&\Longrightarrow \begin{pmatrix}1 & x\end{pmatrix}\begin{pmatrix}\hat{\beta_0}-\beta_0 \\ \hat{\beta_1}-\beta_1\end{pmatrix}\approx \mathcal{N}\left(0, \begin{pmatrix}1 & x\end{pmatrix}\boldsymbol{V}(\boldsymbol{\beta})^{-1}\begin{pmatrix}1 \\ x\end{pmatrix}\right) \\
&\Longrightarrow (\hat{\beta}_0 +\hat{\beta_1}x)-(\beta_0+\beta_1x) \approx \mathcal{N}\left(0, \sigma_0^2 + 2\gamma x+\sigma_{1}^2x^2\right) \\
&\Longrightarrow \frac{(\hat{\beta}_0 +\hat{\beta_1}x)-(\beta_0+\beta_1x)}{\sqrt{\sigma_0^2 + 2\gamma x+\sigma_{1}^2x^2}} \approx \mathcal{N}\left(0, 1\right) \\
\end{align*}
$$

En rempla√ßant, les coefficients de la matrice
$\boldsymbol{V}(\boldsymbol{\beta})^{-1}$ par ceux estim√©s, on a :

$$
\begin{align*}
\tiny
& \mathbb{P}\left(q_{\alpha/2}^{\mathcal{N}(0,1)} \leq \frac{(\hat{\beta}_0 +\hat{\beta_1}x)-(\beta_0+\beta_1x)}{\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2}} \leq q_{1-\alpha/2}^{\mathcal{N}(0,1)} \right) \simeq 1- \alpha \\
&\Rightarrow \mathbb{P}\left(q_{\alpha/2}^{\mathcal{N}(0,1)}\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2} \leq \underbrace{(\hat{\beta}_0 +\hat{\beta_1}x)}_{\textrm{logit}(\hat{p}(x))}-\underbrace{(\beta_0+\beta_1x)}_{\textrm{logit}(p(x))} \leq q_{1-\alpha/2}^{\mathcal{N}(0,1)\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2}} \right) \simeq 1- \alpha \\
&\Rightarrow \mathbb{P}\left(\hat{\beta}_0 +\hat{\beta_1}x-q_{1-\alpha/2}^{\mathcal{N}(0,1)}\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2} \leq \beta_0+\beta_1x \leq \hat{\beta}_0 +\hat{\beta_1}x -q_{\alpha/2}^{\mathcal{N}(0,1)}\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2} \right) \simeq 1- \alpha \\
&\Rightarrow \mathbb{P}\left(\textrm{logit}^{-1}\left(\hat{\beta}_0 +\hat{\beta_1}x-q_{1-\alpha/2}^{\mathcal{N}(0,1)}\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2}\right) \leq p(x) \leq \textrm{logit}^{-1}\left(\hat{\beta}_0 +\hat{\beta_1}x -q_{\alpha/2}^{\mathcal{N}(0,1)}\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2} \right)\right) \simeq 1- \alpha \\
&\Rightarrow \textrm{IC}_{1-\alpha}\left[p(x)\right] \simeq \left[\textrm{logit}^{-1}\left(\hat{\beta}_0 +\hat{\beta_1}x-q_{1-\alpha/2}^{\mathcal{N}(0,1)}\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2}\right) ; \ \textrm{logit}^{-1}\left( \hat{\beta}_0 +\hat{\beta_1}x+q_{1-\alpha/2}^{\mathcal{N}(0,1)}\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2}\right) \right]
\end{align*}
$$

Pour faire ce calcul dans {{< iconify logos:r-lang >}} deux options sont envisageables :

-   On peut calculer les bornes de l'intervalle de confiance avec
    l'expression qu'on vient d'obtenir.
-   On peut utiliser l'option `type='link'` et `se=TRUE` dans la
    fonction `predict` qui permet de calculer les termes
    $\sqrt{\hat{\sigma}_0^2 + 2\hat{\gamma} x+\hat{\sigma}_{1}^2x^2}$
    via l'attribut `se.fit` et $\widehat{\beta}_0+\widehat{\beta}_1x$
    via l'attribut `fit`.

::: panel-tabset
### √Ä la main

::: {.panel-tabset group="language"}
#### Base R

```{webr}
#| envir: baser
#| autorun: true
#| fig-width: 9
# Valeurs observ√©es
plot(
  data_chdage$age, as.numeric(data_chdage$chd)-1, 
  xlab = "√Çge", 
  ylab = "Valeur observ√©e ou probabilit√© pr√©dite", 
  pch = 19, 
  col = "black", 
  ylim = c(-0.2, 1.2) # Ajustement des limites pour inclure les segments
)
grid()

# Ajouter les segments horizontaux des valeurs pr√©dites Q7
segments(
  x0 = data_milieu_classe_prop$borne_inf, 
  x1 = data_milieu_classe_prop$borne_sup, 
  y0 = data_milieu_classe_prop$proportion, 
  y1 = data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  lwd = 1.2
)

# Ajouter les points aux bornes inf√©rieures
points(
  data_milieu_classe_prop$borne_inf, data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  pch = 19, 
  cex = 1.5
)

# Ajouter les points aux bornes sup√©rieures (vides √† l'int√©rieur)
points(
  data_milieu_classe_prop$borne_sup, data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  pch = 21, 
  bg = "white", 
  cex = 1.5
)

# Ajout des pr√©dictions de la Q8
fake_data <- data.frame(age = seq(from = 20, to = 70, by = 0.1))
fake_data$p_hat <- predict(modele_logit, newdata=fake_data, type = "response")

beta_mle <- matrix(modele_logit$coefficients, nrow=2)

W_beta <- diag(
  exp(beta_mle[1,1]+data_chdage$age*beta_mle[2,1])/(1+exp(beta_mle[1,1]+data_chdage$age*beta_mle[2,1]))**2
)

n_obs <- nrow(data_chdage)
design_matix <- matrix(
  data = c(rep(1.0, length = n_obs), data_chdage$age),
  ncol = 2,
  byrow = FALSE
)
Vn <- t(design_matix) %*% W_beta  %*%  design_matix

Vn_inv <- solve(Vn)

fake_data$p_hat_inf <- logit_inv(
  modele_logit$coefficients[1] +
  fake_data$age*modele_logit$coefficients[2] -
  qnorm(0.975, mean = 0, sd = 1)*sqrt(
    Vn_inv[1,1]+
      2*Vn_inv[1,2]*fake_data$age+
      Vn_inv[2,2]*(fake_data$age**2)
  )
)
  
fake_data$p_hat_sup <- logit_inv(
  modele_logit$coefficients[1] +
  fake_data$age*modele_logit$coefficients[2] +
  qnorm(0.975, mean = 0, sd = 1)*sqrt(
    Vn_inv[1,1]+
      2*Vn_inv[1,2]*fake_data$age+
      Vn_inv[2,2]*(fake_data$age**2)
  )
)

lines(
  x = fake_data$age,
  y = fake_data$p_hat,
  col = "#3854A6", 
  lwd = 1.2
)

polygon(
  c(fake_data$age, rev(fake_data$age)),
  c(fake_data$p_hat_sup, rev(fake_data$p_hat_inf)), 
  col = rgb(0, 0, 1, 0.2),
  border = NA
)

# L√©gende
legend(
  "bottom", 
  legend = c("Valeur observ√©e", "Probabilit√© pr√©dite (Q7)", "Probabilit√© pr√©dite (Q8)"), 
  pch = c(19, NA, NA), 
  lty = c(NA, 1, 1), 
  col = c("black", "#F24B4B", "#3854A6"), 
  pt.bg = c(NA, "white", "white"), 
  horiz = TRUE, 
  bty = "n"
)
```

#### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
beta_mle <- matrix(modele_logit$coefficients, nrow=2)

W_beta <- diag(
  exp(beta_mle[1,1]+data_chdage$age*beta_mle[2,1])/(1+exp(beta_mle[1,1]+data_chdage$age*beta_mle[2,1]))**2
)

n_obs <- nrow(data_chdage)
design_matix <- matrix(
  data = c(rep(1.0, length = n_obs), data_chdage$age),
  ncol = 2,
  byrow = FALSE
)
Vn <- t(design_matix) %*% W_beta  %*%  design_matix

Vn_inv <- solve(Vn)

fake_data$p_hat_inf <- logit_inv(
  modele_logit$coefficients[1] +
  fake_data$age*modele_logit$coefficients[2] -
  qnorm(0.975, mean = 0, sd = 1)*sqrt(
    Vn_inv[1,1]+
      2*Vn_inv[1,2]*fake_data$age+
      Vn_inv[2,2]*(fake_data$age**2)
  )
)
  
fake_data$p_hat_sup <- logit_inv(
  modele_logit$coefficients[1] +
  fake_data$age*modele_logit$coefficients[2] +
  qnorm(0.975, mean = 0, sd = 1)*sqrt(
    Vn_inv[1,1]+
      2*Vn_inv[1,2]*fake_data$age+
      Vn_inv[2,2]*(fake_data$age**2)
  )
)

graphique_q20 <- graphique_q19 +
  geom_ribbon(
    data = fake_data,
    mapping = aes(x = age, ymin=p_hat_inf, ymax=p_hat_sup),
    alpha = 0.5,
    fill = "#3854A6"
  )

graphique_q20
```
:::

### En utilisant `predict`

::: {.panel-tabset group="language"}
#### Base R

```{webr}
#| envir: baser
#| autorun: true
#| fig-width: 9
# Valeurs observ√©es
plot(
  data_chdage$age, as.numeric(data_chdage$chd)-1, 
  xlab = "√Çge", 
  ylab = "Valeur observ√©e ou probabilit√© pr√©dite", 
  pch = 19, 
  col = "black", 
  ylim = c(-0.2, 1.2) # Ajustement des limites pour inclure les segments
)
grid()

# Ajouter les segments horizontaux des valeurs pr√©dites Q7
segments(
  x0 = data_milieu_classe_prop$borne_inf, 
  x1 = data_milieu_classe_prop$borne_sup, 
  y0 = data_milieu_classe_prop$proportion, 
  y1 = data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  lwd = 1.2
)

# Ajouter les points aux bornes inf√©rieures
points(
  data_milieu_classe_prop$borne_inf, data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  pch = 19, 
  cex = 1.5
)

# Ajouter les points aux bornes sup√©rieures (vides √† l'int√©rieur)
points(
  data_milieu_classe_prop$borne_sup, data_milieu_classe_prop$proportion, 
  col = "#F24B4B", 
  pch = 21, 
  bg = "white", 
  cex = 1.5
)

# Ajout des pr√©dictions de la Q8
fake_data <- data.frame(age = seq(from = 20, to = 70, by = 0.1))
fake_data$p_hat <- predict(modele_logit, newdata=fake_data, type = "response")

predictions <- predict(modele_logit, newdata=fake_data, type = "link", se = TRUE)
fake_data$p_hat_inf <- logit_inv(
  predictions$fit-qnorm(0.975, mean = 0, sd = 1)*predictions$se.fit
)
fake_data$p_hat_sup <- logit_inv(
  predictions$fit+qnorm(0.975, mean = 0, sd = 1)*predictions$se.fit
)

lines(
  x = fake_data$age,
  y = fake_data$p_hat,
  col = "#3854A6", 
  lwd = 1.2
)

polygon(
  c(fake_data$age, rev(fake_data$age)),
  c(fake_data$p_hat_sup, rev(fake_data$p_hat_inf)), 
  col = rgb(0, 0, 1, 0.2),
  border = NA
)

# L√©gende
legend(
  "bottom", 
  legend = c("Valeur observ√©e", "Probabilit√© pr√©dite (Q7)", "Probabilit√© pr√©dite (Q8)"), 
  pch = c(19, NA, NA), 
  lty = c(NA, 1, 1), 
  col = c("black", "#F24B4B", "#3854A6"), 
  pt.bg = c(NA, "white", "white"), 
  horiz = TRUE, 
  bty = "n"
)
```

#### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
predictions <- predict(modele_logit, newdata=fake_data, type = "link", se = TRUE)
fake_data$p_hat_inf <- logit_inv(
  predictions$fit-qnorm(0.975, mean = 0, sd = 1)*predictions$se.fit
)
fake_data$p_hat_sup <- logit_inv(
  predictions$fit+qnorm(0.975, mean = 0, sd = 1)*predictions$se.fit
)
  
graphique_q20 <- graphique_q19 +
  geom_ribbon(
    data = fake_data,
    mapping = aes(x = age, ymin=p_hat_inf, ymax=p_hat_sup),
    alpha = 0.5,
    fill = "#3854A6"
  )
graphique_q20
```
:::

:::

:::

:::
