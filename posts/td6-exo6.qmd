---
title: "TD 6 - Exercice 6 - Fourmis"
lang: fr
author: "Théo Leroy"
date: "19 novembre 2024"
format:
  live-html:
    code-background: true
    toc: true
    page-layout: full
webr:
  render-df: gt-interactive
  resources:
    - ./../data/Fourmis.txt
  packages:
      - dplyr
      - readr
      - ggplot2
      - gridExtra
      - tidyr
      - MASS
editor: 
  markdown: 
    wrap: 72
---

## Question 1

On charge les données du fichier `Fourmis.txt` en R sous forme de
`data.frame`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
data_fourmis <- read.csv(
  file = 'data/Fourmis.txt',
  sep = ",",
  header = TRUE,
  colClasses = c("integer", "numeric", "factor", "factor")
)
data_fourmis
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
data_fourmis <- readr::read_delim(
  file = "data/Fourmis.txt",
  col_types = readr::cols(
    readr::col_integer(),
    readr::col_number(),
    readr::col_factor(level = c("FLWT", "FTWT", "GPWT", "INWT")),
    readr::col_factor(level = c("Dry", "Wet"))
  ),
  delim = ","
)
data_fourmis
```
:::

La variable `Effectifs` correspondant au nombre d'espèces différentes de
fourmis dans l'échantillon prélevé est une variable de comptage. On
l'importe comme `integer`.

La variable `Weight` contient le poids des échantillons.C'est une
variable quantitative, on l'importe en `numeric`.

La variable `Site` indique la provenance des différents échantillons
(`GPWT` : forêt de plateau, `FLWT` forêt de lianes, `FTWT` forêt de
transition, et `INWT` forêt d'Iselberg). C'est une variable
catégorielle. On l'importe en `factor`.

La variable `Conditions` nous renseigne sur les conditions de recueil de
l'échantillon. C'est une variable catégorielle avec deux modalités :
`Dry` (sec) et `Wet` (humide) qu'on importe donc en `factor`.

## Question 2

### Lien entre `Weight` et `Effectifs`

::: {.panel-tabset group="language"}
#### Base R

```{webr}
#| envir: baser
#| autorun: true
plot(
  x = data_fourmis$Weight,
  y = data_fourmis$Effectifs, 
  xlab = "Poids de l'échantillon", 
  ylab = "Nombre d'espèces différentes",
)
grid()
```

#### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
ggplot2::ggplot(
  data = data_fourmis,
  mapping = ggplot2::aes(x = Weight, y = Effectifs)
) +
  ggplot2::geom_point() +
  ggplot2::labs(
    x = "Poids de l'échantillon",
    y = "Nombre d'espèces différentes"
  ) +
  ggplot2::theme_light() 
```
:::

Ce nuage de point ne permet pas de mettre en évidence un lien entre le
poids de l'échantillon et l'effectif de fourmis présent.

::: {.panel-tabset group="language"}
#### Base R

```{webr}
#| envir: baser
#| autorun: true
par(mfrow = c(2,2))
lapply(
  X = levels(data_fourmis$Site),
  FUN = function(site){
    plot(
      x = data_fourmis[data_fourmis$Site == site, "Weight"],
      y = data_fourmis[data_fourmis$Site == site, "Effectifs"],
      xlab = "Poids de l'échantillon", 
      ylab = "Nombre d'espèces différentes",
      main = site
    )
    grid()
  }
) |> invisible()
```

#### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
par(mfrow = c(2,2))
g <- lapply(
  X = levels(data_fourmis$Site),
  FUN = function(site){
    ggplot2::ggplot(
      data = data_fourmis |> dplyr::filter(Site == site),
      mapping = ggplot2::aes(x = Weight, y = Effectifs, main = site)
    ) +
      ggplot2::geom_point() +
      ggplot2::labs(
        x = "Poids de l'échantillon",
        y = "Nombre d'espèces différentes"
      ) +
      ggplot2::ggtitle(label= site) + 
      ggplot2::theme_light() 
  }
)
gridExtra::grid.arrange(grobs = g, layout_matrix = matrix(1:4, ncol = 2))
```
:::

En distinguant par type de forêt un lien croissant semble exister pour
les forêts `FLWT` et `GPWT`.

### Lien entre `Site` et `Effectifs`

::: {.panel-tabset group="language"}
#### Base R

```{webr}
#| envir: baser
#| autorun: true
boxplot(
  Site ~ Effectifs,
  data = data_fourmis,
  main = "Distribution du nombre d'espèces de fourmis en fonction du site de prélèvement"
)
```

#### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
ggplot2::ggplot(
  data = data_fourmis,
  mapping = ggplot2::aes(x = Site, y = Effectifs)
) +
  ggplot2::geom_boxplot() +
  ggplot2::labs(
    title = "Distribution du nombre d'espèces de fourmis en fonction du site de prélèvement"
  ) +
  ggplot2::theme_minimal()
```
:::

Un lien semble exister entre le type de forêt et le nombre d'espèces de
fourmis.

### Lien entre `Conditions` et `Effectifs`

::: {.panel-tabset group="language"}
#### Base R

```{webr}
#| envir: baser
#| autorun: true
boxplot(
  Conditions ~ Effectifs,
  data = data_fourmis,
  main = "Distribution du nombre d'espèces de fourmis en fonction des conditions de recueil"
)
```

#### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
ggplot2::ggplot(
  data = data_fourmis,
  mapping = ggplot2::aes(x = Conditions, y = Effectifs)
) +
  ggplot2::geom_boxplot() +
  ggplot2::labs(
    title = "Distribution du nombre d'espèces de fourmis en fonction des conditions de recueil"
  ) +
  ggplot2::theme_minimal()
```
:::

Aucune relation ne semble exister entre les conditions de recueil et le
nombre d'espèces de fourmis.

## Question 3

Le modèle log-linéaire de Poisson de la variables `Effectifs` en
fonction de toutes les variables à disposition s'écrit :

$$
\begin{align*}
\texttt{Effectifs}&|(\texttt{Weight}, \texttt{Site},\texttt{Conditions}) \sim \mathcal{P}(\lambda(\texttt{Weight}, \texttt{Site},\texttt{Conditions}))
\end{align*}
$$

avec

$$
\begin{align*}
\textrm{log}\left(\lambda(\texttt{Weight}, \texttt{Site},\texttt{Conditions})\right) = &\ \ \ \ \ 
\beta_0 \\ 
&+ \beta_1\texttt{Weight} \\
&+ \beta_2\textbf{1}_{\texttt{Site}=\texttt{FTWT}}+\beta_3\textbf{1}_{\texttt{Site}=\texttt{GPWT}}+\beta_4\textbf{1}_{\texttt{Site}=\texttt{INWT}} \\
&+ \beta_5\textbf{1}_{\texttt{Conditions}=\texttt{Wet}} \\
&+ \beta_6\texttt{Weight}\textbf{1}_{\texttt{Site}=\texttt{FTWT}}+\beta_7\texttt{Weight}\textbf{1}_{\texttt{Site}=\texttt{GPWT}}+\beta_8\texttt{Weight}\textbf{1}_{\texttt{Site}=\texttt{INWT}} \\
&+ \beta_9\texttt{Weight}\textbf{1}_{\texttt{Conditions}=\texttt{Wet}} \\
&+ \beta_{10}\textbf{1}_{\texttt{Site}=\texttt{FTWT}}\textbf{1}_{\texttt{Conditions}=\texttt{Wet}}+\beta_{11}\textbf{1}_{\texttt{Site}=\texttt{GPWT}}\textbf{1}_{\texttt{Conditions}=\texttt{Wet}}+\beta_{12}\textbf{1}_{\texttt{Site}=\texttt{INWT}}\textbf{1}_{\texttt{Conditions}=\texttt{Wet}} \\ 
&+ \beta_{13}\texttt{Weight}\textbf{1}_{\texttt{Site}=\texttt{FTWT}}\textbf{1}_{\texttt{Conditions}=\texttt{Wet}} +\beta_{14}\texttt{Weight}\textbf{1}_{\texttt{Site}=\texttt{GPWT}}\textbf{1}_{\texttt{Conditions}=\texttt{Wet}}+\beta_{15}\texttt{Weight}\textbf{1}_{\texttt{Site}=\texttt{INWT}}\textbf{1}_{\texttt{Conditions}=\texttt{Wet}}  \\
\end{align*}
$$

Il y a 16 paramètres à estimer.

On peut représenter la modélisation de $\textrm{log}\left(\lambda(\texttt{Weight}, \texttt{Site},\texttt{Conditions})\right)$ dans un tableau à double entrée.

|   | $\texttt{Conditions}=\texttt{"Dry"}$ | $\texttt{Conditions}=\texttt{"Wet"}$ |
|-----------------|----------------------|----------------------------------|
| $\texttt{Site}=\texttt{"FLWT"}$ | $\beta_0+\beta_1\texttt{Weight}$  | $\beta_0+\beta_5+(\beta_1+\beta_9)\texttt{Weight}$  |
| $\texttt{Site}=\texttt{"FTWT"}$ | $\beta_0+\beta_2+(\beta_1+\beta_{6})\texttt{Weight}$ | $\beta_0+\beta_2+\beta_5+\beta_{10}+(\beta_1+\beta_6+\beta_9+\beta_{13})\texttt{Weight}$  |
| $\texttt{Site}=\texttt{"GPWT"}$ | $\beta_0+\beta_3+(\beta_1+\beta_{7})\texttt{Weight}$ | $\beta_0+\beta_3+\beta_5+\beta_{11}+(\beta_1+\beta_7+\beta_9+\beta_{14})\texttt{Weight}$ |
| $\texttt{Site}=\texttt{"INWT"}$ | $\beta_0+\beta_4+(\beta_1+\beta_{8})\texttt{Weight}$ | $\beta_0+\beta_4+\beta_5+\beta_{12}+(\beta_1+\beta_8+\beta_9+\beta_{15})\texttt{Weight}$ |

On ajuste le modèle avec la fonction `glm`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
modele_q3_full <- glm(
  formula = Effectifs ~ Weight*Site*Conditions,
  family = poisson(),
  data = data_fourmis
)
summary(modele_q3_full)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
modele_q3_full <- glm(
  formula = Effectifs ~ Weight*Site*Conditions,
  family = poisson(),
  data = data_fourmis
)
summary(modele_q3_full)
```
:::

Une analyse rapide des résultats de la sortie donnée par la fonction `summary` met en évidence de nombreux coefficients non significatifs. Cependant, l’interaction triple semblerait pertinente car certains coefficients associés sont significatifs au seuil 5 %. Ainsi, le coefficient associé à la variable `Weight` ne varie pas de manière significative lorsqu’on considère uniquement le site ou les conditions séparément (cf. interactions doubles) mais il semble varier quand on prend en compte à la fois `Site` et `Conditions`.

On peut chercher des modèles plus simples à partir des critères `BIC` ou `AIC`. On mettre en oeuvre une procédure de sélection exhaustive ici vu le nombre de variables.


::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
combinaisons <- expand.grid(list(
  Weight = c(FALSE, TRUE),
  Site =  c(FALSE, TRUE),
  Conditions =  c(FALSE, TRUE),
  `Weight:Site` =  c(FALSE, TRUE),
  `Weight:Conditions` = c(FALSE, TRUE),
  `Site:Conditions` = c(FALSE, TRUE),
  `Weight:Site:Conditions` = c(FALSE, TRUE)
))
# On exclut les combinaisons qui n'ont pas de sens c'est à dire 
# inlure une interraction alors que tous les effets simples ne pas présents
combinaisons <- combinaisons[
  !ifelse(
    combinaisons$`Weight:Site`,
    !(combinaisons$Weight & combinaisons$Site),
    FALSE
  ),
]
combinaisons <- combinaisons[
  !ifelse(
    combinaisons$`Weight:Conditions`,
    !(combinaisons$Weight & combinaisons$Conditions),
    FALSE
  ),
]
combinaisons <- combinaisons[
  !ifelse(
    combinaisons$`Site:Conditions`,
    !(combinaisons$Site & combinaisons$Conditions),
    FALSE
  ),
]
#ou inclure l’interaction triple sans les interactions doubles 
combinaisons <- combinaisons[
  !ifelse(
    combinaisons$`Weight:Site:Conditions`,
    !(combinaisons$`Weight:Site` & combinaisons$`Weight:Conditions` & combinaisons$`Site:Conditions`),
    FALSE
  ),
]
combinaisons
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
combinaisons <- expand.grid(
  Weight = c(FALSE, TRUE),
  Site = c(FALSE, TRUE),
  Conditions = c(FALSE, TRUE),
  `Weight:Site` = c(FALSE, TRUE),
  `Weight:Conditions` = c(FALSE, TRUE),
  `Site:Conditions` = c(FALSE, TRUE),
  `Weight:Site:Conditions` = c(FALSE, TRUE)
) |>
  tibble::as_tibble() %>%
  # Exclusion des combinaisons non valides
  dplyr::filter(
    # Vérification pour "Weight:Site"
    !(`Weight:Site` & !(Weight & Site)),
    # Vérification pour "Weight:Conditions"
    !(`Weight:Conditions` & !(Weight & Conditions)),
    # Vérification pour "Site:Conditions"
    !(`Site:Conditions` & !(Site & Conditions)),
    # Vérification pour "Weight:Site:Conditions"
    !(`Weight:Site:Conditions` & 
        !(`Weight:Site` & `Weight:Conditions` & `Site:Conditions`))
  )

combinaisons
```
:::

Il y a 19 modèles à estimer.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
# On ajuste les 19 modèles et on calcule les différents BIC et AIC associés
lapply(
  X = seq.int(nrow(combinaisons)),
  FUN = function(i){
    termes <- colnames(combinaisons[i,])[as.logical(combinaisons[i,])]
    if(length(termes) == 0L){
      formule <- as.formula("Effectifs ~ 1")
    } else {
      formule <- paste0(
        "Effectifs ~ ",
        paste0(termes, collapse = "+")
      ) |> as.formula()
    }
    
    estimation <-  glm(
      formula = formule,
      family = poisson(),
      data = data_fourmis
    )
    data.frame(
      termes = paste0(termes, collapse = "+"),
      AIC = AIC(estimation),
      BIC = BIC(estimation)
    )
  }
) |> do.call(what = rbind.data.frame)

```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
lapply(
  X = seq.int(nrow(combinaisons)),
  FUN = function(i){
    termes <- colnames(combinaisons[i,])[as.logical(combinaisons[i,])]
    if(length(termes) == 0L){
      formule <- as.formula("Effectifs ~ 1")
    } else {
      formule <- paste0(
        "Effectifs ~ ",
        paste0(termes, collapse = "+")
      ) |> as.formula()
    }
    
    estimation <-  glm(
      formula = formule,
      family = poisson(),
      data = data_fourmis
    )
    
    tibble::tibble(
      termes = paste0(termes, collapse = "+"),
      AIC = AIC(estimation),
      BIC = BIC(estimation)
    )
  }
) |> dplyr::bind_rows()
```
:::

Le modèle avec interaction triple est préféré avec le critère AIC et le modèle avec seulement `Weight`, `Site`, `Conditions` et l'interaction entre `Site` et `Conditions` est préféré avec le critère BIC. Par souci de parcimonie, on pourrait préférer le modèle sans interaction triple.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
modele_q3_sel <- glm(
  formula = Effectifs ~ Weight+Site+Conditions+Site:Conditions,
  family = poisson(),
  data = data_fourmis
)
summary(modele_q3_sel)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
modele_q3_sel <- glm(
  formula = Effectifs ~ Weight+Site+Conditions+Site:Conditions,
  family = poisson(),
  data = data_fourmis
)
summary(modele_q3_sel)
```
:::

## Question 4

On adopte la même démarche. On estime d'abord le modèle avec le plus de termes.
On utilise la fonction `glm.nb` du package `MASS`.


::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
modele_q4_full <- MASS::glm.nb(
  formula = Effectifs ~ Weight*Site*Conditions,
  data = data_fourmis
)
summary(modele_q4_full)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
modele_q4_full <- MASS::glm.nb(
  formula = Effectifs ~ Weight*Site*Conditions,
  data = data_fourmis
)
summary(modele_q4_full)
```
:::

Certains tests de Wald indiquent que des coefficients issus de l'interaction triple sont à nouveau significatifs avec une loi binomiale négative. On cherche à nouveau des modèles plus simples.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
# On ajuste les 19 modèles et on calcule les différents BIC et AIC associés
lapply(
  X = seq.int(nrow(combinaisons)),
  FUN = function(i){
    termes <- colnames(combinaisons[i,])[as.logical(combinaisons[i,])]
    if(length(termes) == 0L){
      formule <- as.formula("Effectifs ~ 1")
    } else {
      formule <- paste0(
        "Effectifs ~ ",
        paste0(termes, collapse = "+")
      ) |> as.formula()
    }
    
    estimation <-  MASS::glm.nb(
      formula = formule,
      data = data_fourmis
    )
    data.frame(
      termes = paste0(termes, collapse = "+"),
      AIC = AIC(estimation),
      BIC = BIC(estimation)
    )
  }
) |> do.call(what = rbind.data.frame)

```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
lapply(
  X = seq.int(nrow(combinaisons)),
  FUN = function(i){
    termes <- colnames(combinaisons[i,])[as.logical(combinaisons[i,])]
    if(length(termes) == 0L){
      formule <- as.formula("Effectifs ~ 1")
    } else {
      formule <- paste0(
        "Effectifs ~ ",
        paste0(termes, collapse = "+")
      ) |> as.formula()
    }
    
    estimation <-  MASS::glm.nb(
      formula = formule,
      data = data_fourmis
    )
    
    tibble::tibble(
      termes = paste0(termes, collapse = "+"),
      AIC = AIC(estimation),
      BIC = BIC(estimation)
    )
  }
) |> dplyr::bind_rows()
```
:::


Le modèle avec `Weight`, `Site`, `Conditions` et l'interaction entre `Site` et `Conditions` est préféré avec le critère AIC et modèle avec  `Weight` et `Site` pour le BIC.



```{webr}
#| envir: baser
#| autorun: true
modele_q4_sel <- MASS::glm.nb(
  formula = Effectifs ~ Weight+Site+Conditions+Site:Conditions,
  family = poisson(),
  data = data_fourmis
)
summary(modele_q3_sel)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
modele_q4_sel <- MASS::glm.nb(
  formula = Effectifs ~ Weight+Site+Conditions+Site:Conditions,
  family = poisson(),
  data = data_fourmis
)
summary(modele_q3_sel)
```
:::

## Question 5

L'odds de l'évènement
$\texttt{impair}\leq k|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life})$
est :

$$
\begin{align*}
\texttt{odds}_k(\textbf{x}) &= \frac{\mathbb{P}(\texttt{impair}\leq k|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))}{1-\mathbb{P}(\texttt{impair}\leq k|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))} \\
&=\exp\left(\textrm{logit}\left(\mathbb{P}(\texttt{impair}\leq k | (\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))\right)\right) \\
&= \exp\left(\beta_0^{(k)}+\beta_1x_{\texttt{ses}=1}+\beta_2x_\texttt{life} \right)
\end{align*}
$$

Ainsi pour un individu avec des caractéristiques
$\textbf{x}=(\texttt{ses}=1, \texttt{life}=x_{\texttt{life}})$ et un
autre individu avec les caractéristiques
$\textbf{x}'=(\texttt{ses}=0, \texttt{life}=x_{\texttt{life}})$, on a :

$$\texttt{OR}(\textbf{x},\textbf{x}') = \frac{\texttt{odds}_k(\textbf{x})}{\texttt{odds}_k(\textbf{x}')}=\frac{\exp(\beta_0^{(k)}+\beta_1+\beta_2x_\texttt{life})}{\exp(\beta_0^{(k)}+\beta_2x_\texttt{life})}=\exp(\beta_1)$$

Ainsi un estimateur de $\texttt{OR}(\textbf{x},\textbf{x}')$ est

$\exp\left(\hat{\beta}_1\right)$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
exp(modele_q4@coefficients[4])
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
exp(modele_q4@coefficients[4])
```
:::

::: {.callout-note appearance="simple"}
### Remarque

Les objets retournés par la méthode `vglm` sont de type S4 contrairement
à ceux retournés par `glm` (qui sont de type S3). Pour accéder au
attributs, on utilise le symbole `@` au lieu de `$`.
:::

Cette quantité permet d'évaluer l'évolution de la côte sur la santé
mentale lorsqu'une personne a un statut socio-économique par rapport a
quelqu'un qui a un statut économique faible toutes choses égales par
ailleurs.

On peut dire :

**"Toutes choses égales par ailleurs, lorsqu'un indivdu passe d'un
statut socio-économique faible à élevé, l'odds d'avoir au plus un
certain niveau de dégénérescence mentale est multiplié par 3"**.

Les individus avec un statut économique plus élevés ont donc toutes
choses égales par ailleurs une meilleur santé mentale.

::: callout-warning
**Il faut faire attention à ne pas interpréter à tort cette évolution
sur l'odds (en français cote) comme une évolution sur le risque (c'est à
dire sur la probabilité de l'évènement qui nous intéresse)**. Ici, il
s'agirait de la probabilité d'avoir au plus un certain niveau de
dégénérescence mentale :
$P(\texttt{impair}\leq k|\textbf{X}=\textbf{x})$.

On ne peut donc pas dire : ~~"Toutes choses égales par ailleurs,
lorsqu'un indivdu passe d'un statut socio-économique faible à élevé, la
probabilité d'avoir au plus un certain niveau de dégénérescence mentale
est multipliée par 3"~~

La probabilité et la cote sont deux quantités différentes. La première
est bornée entre 0 et 1 contrairement à la seconde qui n'a pas de
maximum. On peut le voir visuellement avec cette relation liant les deux
sur le graphique ci-dessous qui se différencie de la première
bissectrice du plan.

```{webr}
#| envir: tdv
#| autorun: true
proba <- seq(from=0,to=0.9,by=0.05)
cote <- proba/(1-proba)
ggplot2::ggplot(
  mapping = aes(x=x,y=y),
  data = data.frame(
    x=proba,
    y=cote
  )
) +
  ggplot2::geom_line(color="red") +
  ggplot2::geom_line(
    mapping = ggplot2::aes(x=x,y=y),
    data=data.frame(x=proba,y=proba),
    color="black"
  ) +
  ggplot2::labs(
    title = "Lien (en rouge) entre odds et probabilité d'un évènement",
    x = "Probabilité d'un évènement",
    y = "Côte/Odds d'un évènement"
  ) +
  ggplot2::theme_minimal()
```

Cependant, on peut remarquer sur ce graphique qu'on peut faire cette
approximation pour des faibles probabilités (par exemple pour des
probabilités inférieures à 10 %) ou plus formellement avec un
développement limité à l'ordre 1.

$$
\frac{p}{1-p} \underset{p \to 0}{=} p + o(p)
$$

Dans cet exercice avec ce modèle cumulatif, l'emploi de cette
approximation n'est pas acceptable car les évènements d'avoir au plus un
certain niveau de dégénérescence mentale ne sont pas rares.

```{webr}
#| envir: tdv
#| autorun: true
x_life <- seq(from=0,to=9,by=0.25)
logit_proba_predites_cumulees <-  predict(
  object = modele_q4,
  newdata = data.frame(ses = 0, life = x_life),
  type = "link"
)
proba_predites_cumulees <- as.data.frame(apply(
  X = logit_proba_predites_cumulees,
  MARGIN = 2,
  FUN = function(x){exp(x)/(1+exp(x))}
))
colnames(proba_predites_cumulees) <- c(
  "P[impair <= 1]",
  "P[impair <= 2]",
  "P[impair <= 3]"
)

proba_predites_cumulees$life <- x_life

proba_predites_cumulees_long <-  proba_predites_cumulees |>
  tidyr::gather(key="type_proba", value="valeur_proba", -life)

ggplot2::ggplot(
  mapping = aes(x=life,y=valeur_proba, color=type_proba),
  data = proba_predites_cumulees_long
) +
  ggplot2::geom_line() +
  ggplot2::labs(
    title = "Probabilités cumulées prédites par le modèle selon la variable life (ses=0)",
    x = "life",
    y = "Probabilité", 
    colour = "Type de probabilité"
  ) +
  ggplot2::theme_minimal()
```
:::

:::::::::::::: {.content-hidden when-format="html"}
## Question 6

L'intervalle de confiance asymptotique au niveau de confiance
$1 − \alpha$ pour $\hat{\beta_1}$ est donnée par :
$$\left[\hat{\beta}_1 - q_{1-\alpha/2}^{\mathcal{N}(0,1)}\hat{\sigma}_1 \ ; \ \hat{\beta}_1 + q_{1-\alpha/2}^{\mathcal{N}(0,1)}\hat{\sigma}_1 \right]$$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
alpha <- 0.05
beta_mle_1 <- modele_q4@coefficients[4]
sigma_est_1 <- sqrt(vcov(modele_q4)[4,4])
quantile_alpha <- qnorm(mean = 0, sd = 1, p = 1-alpha/2) 

paste0(
  "[",
  beta_mle_1-quantile_alpha*sigma_est_1,
  " ; ",
  beta_mle_1+quantile_alpha*sigma_est_1,
  "]"
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
alpha <- 0.05
beta_mle_1 <- modele_q4@coefficients[4]
sigma_est_1 <- sqrt(vcov(modele_q4)[4,4])
quantile_alpha <- qnorm(mean = 0, sd = 1, p = 1-alpha/2) 

paste0(
  "[",
  beta_mle_1-quantile_alpha*sigma_est_1,
  " ; ",
  beta_mle_1+quantile_alpha*sigma_est_1,
  "]"
)
```
:::

On pouvait aussi utiliser la fonction `confint`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
confint(modele_q4)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
confint(modele_q4)
```
:::

## Question 7

Par monotonie de la fonction $\exp$, on peut construire un intervalle de
confiance en passant à l'exponentielle dans les bornes de l'IC
précédent.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
exp(confint(modele_q4)["ses",])
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
exp(confint(modele_q4)["ses",])
```
:::

## Question 8

D'après la sortie obtenue à la [question 4](#question-4) et les p-valeur
des tests de Wald, le coefficient $\beta_1$ est non significatif au
seuil d'erreur 5 % mais il est significatif au seuil 10 %.

## Question 9 {#question-9}

On peut ajouter un terme d'interaction entre deux variables avec
l'opérateur `:` afin d'évaluer si l'effet du nombre et de l'intensité
des bouleversements connus est le même sur la santé mentale quel que
soit le niveau socio-économique.

Ce nouveau modèle de régression cumulatif proportionnel avec terme
d'interaction s'écrit :

$$
\begin{align*}
\texttt{impair}&|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}) \sim \mathcal{M}( \\
&n=1, \\
&\mathbb{P}(\texttt{impair}\leq 1|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life})), \\
&\mathbb{P}(\texttt{impair}\leq 2|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))-\mathbb{P}(\texttt{impair}\leq 1|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life})), \\
&\mathbb{P}(\texttt{impair}\leq 3|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))-\mathbb{P}(\texttt{impair}\leq 2|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life})), \\
&1 - \mathbb{P}(\texttt{impair}\leq 3|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))) \\
\end{align*}
$$

avec pour tout $k \in \{1,2,3\}$

$$
 \textrm{logit}\left(\mathbb{P}(\texttt{impair}\leq k | (\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))\right) = \alpha_0^{(k)}+\alpha_1x_{\texttt{ses}}+\alpha_2x_\texttt{life}+\alpha_3x_{\texttt{ses}=1}x_\texttt{life}
$$

Il y a 6 paramètres à estimer : $\alpha_0^{(1)}$, $\alpha_0^{(2)}$,
$\alpha_0^{(3)}$, $\alpha_1$ et $\alpha_2$, $\alpha_3$.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
modele_q9 <- vglm(
  formula = impair ~ ses + life + ses:life,
  family = cumulative(parallel = TRUE),
  data = data_mental
)
summary(modele_q9)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
modele_q9 <- VGAM::vglm(
  formula = impair ~ ses + life + ses:life,
  family = cumulative(parallel = TRUE),
  data = data_mental
)
summary(modele_q9)
```
:::

Pour évaluer la pertinence de ce terme d'intéraction, on peut réaliser
un test du rapport de vraisemblance entre ces deux modèles emboités.

L'hypothèse nulle $H_0$ est $\beta_3=0$

Sous $H_0$, la statistique de test du rapport de vraisemblance :
$$ -2 \ln\left(\frac{L_n^{(\textrm{modele contraint})}}{L_n^{(\textrm{modele non contraint})}}\right) \sim \chi^2(\underbrace{\textrm{nb de coefficients contraints}}_{1})$$

avec :

-   $L_n^{(\textrm{modele contraint})}$ : la vraisemblance du modèle
    contraint par l'hypothèse nulle (il s'agit du modèle estimé à la
    [question 4](#question-4))
-   $L_n^{(\textrm{modele non contraint})}$ : la vraisemblance du modèle
    non contraint ou il faut estimer le coefficient d'intéraction
    $\beta_3$, celui qu'on vient d'estimer dans cette question.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
2*(logLik(modele_q9)-logLik(modele_q4))
qchisq(0.95,1)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
2*(logLik(modele_q9)-logLik(modele_q4))
qchisq(0.95,1)
```
:::

Le quantile 0.95 d'une $\chi^2$ à 1 degrés de liberté est supérieur à la
statistique de test. On ne rejette pas l'hypothèse nulle pour un risque
de première espèce $\alpha=0.05$.

Ainsi, le modèle avec le terme d'intéraction n'est pas significativement
meilleur au seuil d'erreur asymptotique de 5 %.

## Question 10

Le modèle de régression logistique cumulatif sans structure
proportionnelle et sans terme d'intéraction s'écrit :

$$
\begin{align*}
\texttt{impair}&|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}) \sim \mathcal{M}( \\
&n=1, \\
&\mathbb{P}(\texttt{impair}\leq 1|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life})), \\
&\mathbb{P}(\texttt{impair}\leq 2|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))-\mathbb{P}(\texttt{impair}\leq 1|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life})), \\
&\mathbb{P}(\texttt{impair}\leq 3|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))-\mathbb{P}(\texttt{impair}\leq 2|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life})), \\
&1 - \mathbb{P}(\texttt{impair}\leq 3|(\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))) \\
\end{align*}
$$

avec pour tout $k \in \{1,2,3\}$

$$
 \textrm{logit}\left(\mathbb{P}(\texttt{impair}\leq k | (\texttt{ses}=x_\texttt{ses},\texttt{life}=x_\texttt{life}))\right) = \gamma_0^{(k)}+\gamma_1^{(k)}x_{\texttt{ses}}+\gamma_2^{(k)}x_\texttt{life}
$$

Il y a 9 paramètres à estimer : $\gamma_0^{(1)}$, $\gamma_0^{(2)}$,
$\gamma_0^{(3)}$, $\gamma_1^{(1)}$, $\gamma_1^{(2)}$, $\gamma_1^{(3)}$,
$\gamma_2^{(1)}$, $\gamma_2^{(2)}$ et $\gamma_2^{(3)}$.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
modele_q10 <- VGAM::vglm(
  formula = impair~ses+life,
  family = cumulative(parallel = F),
  data=data_mental
)
summary(modele_q10)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
modele_q10 <- VGAM::vglm(
  formula = impair~ses+life,
  family = cumulative(parallel = F),
  data=data_mental
)
summary(modele_q10)
```
:::

À l'image de la [question 9](#question-9), on peut faire un test du
rapport de vraisemblance entre ces deux modèles emboités.

L'hypothèse nulle est
$H_0: \gamma_1^{(1)}=\gamma_1^{(2)}=\gamma_1^{(3)}$ et
$\gamma_2^{(1)}=\gamma_2^{(2)}=\gamma_2^{(3)}$.

Les valeurs de la statistique de test et le quantile de comparaison sont
:

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
2*(logLik(modele_q10)-logLik(modele_q4))
qchisq(0.95,4)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
2*(logLik(modele_q10)-logLik(modele_q4))
qchisq(0.95,4)
```
:::

Quatre coefficients sont contraints dans le modèle avec structure
proportionnelle.

On ne rejette pas $H_0$ car la statistique de test est inférieure au
quantile $q_{0.95}^{\chi^2(4)}$.

Ainsi, le modèle avec la structure non proportionnelle n'est pas
significativement meilleur.

## Question 11

Au vu de la sortie du modèle à odds proportionnels et de l’analyse
descriptive préliminaire, on peut essayer d'enlever la variable `ses`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
modele_q11 <- VGAM::vglm(
  formula = impair~life,
  family = cumulative(parallel = F),
  data = data_mental
)
summary(modele_q10)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
modele_q11 <- VGAM::vglm(
  formula = impair~life,
  family = cumulative(parallel = F),
  data = data_mental
)
summary(modele_q11)
```
:::

On fait un test du rapport de vraisemblance.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
2*(logLik(modele_q11)-logLik(modele_q4))
qchisq(0.95,1)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
2*(logLik(modele_q11)-logLik(modele_q4))
qchisq(0.95,1)
```
:::

Au seuil de 5 %, on est donc amené à privilégier ce modèle plus simple.

## Question 12

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
modele_q12 <- VGAM::vglm(
  formula = impair ~ life,
  family = multinomial,
  data = data_mental
)
summary(modele_q12)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
modele_q12 <- VGAM::vglm(
  formula = impair ~ life,
  family = multinomial,
  data = data_mental
)
summary(modele_q12)
```
:::

Pour comparer avec les modèles précédents, nous ne pouvons pas utiliser
le test du rapport de vraisemblance (ou test de déviance) car les
modèles ne sont pas emboités. Nous pouvons par contre comparer leur
critère AIC et BIC. Pour les deux “meilleurs” modèles de chaque
approche, cela donne.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
AIC(modele_q11)
AIC(modele_q12)
BIC(modele_q11)
BIC(modele_q12)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
AIC(modele_q11)
AIC(modele_q12)
BIC(modele_q11)
BIC(modele_q12)
```
:::

Les deux critères conduisent au choix du modèle obtenu à la question 11.
::::::::::::::
