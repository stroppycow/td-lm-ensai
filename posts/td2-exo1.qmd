---
title: "TD 2 - Exercice 1"
lang: fr
author: "Théo Leroy"
date: "17 septembre 2025"
format:
  live-html:
    code-background: true
    toc: true
    page-layout: full
webr:
  render-df: gt-interactive
  resources:
    - ./../data/eucalyptus.txt
  packages:
      - dplyr
      - readr
      - ggplot2
      - cowplot
fig-align: center
filters: 
  - diagram
  - custom-callout
editor: 
  markdown: 
    wrap: 72
custom-callout:    
  answer:
    color: "#CCCCCC"
    appearance: "minimal"
    title: ""
---

![](/static/img/eucalyptus.jpg){fig-align="center"}

{{< include ./../_extensions/r-wasm/live/_knitr.qmd >}}

On veut expliquer la hauteur des eucalyptus en fonction de leur
circonférence à partir d’une régression linéaire simple. On dispose des
mesures des hauteurs (`ht`) et des circonférences (`circ`) de 1 429
eucalyptus, qui se trouvent dans le fichier `eucalyptus.txt`.

## Question 1

Extraire et représenter les données dans le plan.

::: answer
On charge les données du fichier `eucalyptus.txt` en R sous forme de
`data.frame`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
data_eucalyptus <- read.csv(
  file = "data/eucalyptus.txt",
  header = TRUE,
  sep = " ",
  quote = '"'
)
data_eucalyptus
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
data_eucalyptus <- readr::read_delim(
  file = "data/eucalyptus.txt",
  col_types = "_nnic",
  col_names = c("ht", "circ", "bloc", "clone"),
  skip = 1,
  delim = " ",
  quote = '"'
)
data_eucalyptus
```
:::

Le fichier chargé contient bien 1 429 observations avec les variables
`ht` pour la hauteur (exprimée en mètre) et `circ` pour la circonférence
des eucalyptus.

On représente ces données dans le plan.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
#| fig-align: center
plot(
  x = data_eucalyptus$circ,
  y = data_eucalyptus$ht,
  type ="p",
  xlab = "Circonférence",
  ylab = "Hauteur",
  pch = 3
)
grid()
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
#| fig-align: center
ggplot2::ggplot(
  data = data_eucalyptus,
  mapping = aes(x = circ, y = ht)
) +
  ggplot2::labs(x = "Circonférence", y = "Hauteur") + 
  ggplot2::geom_point()
```
:::

Une régression semble semble indiquée, les points étant disposés
grossièrement le long d'une droite.
:::

## Question 2

Effectuer la régression $y=\beta_1+\beta_2x+\epsilon$ où $y$ représente
la hauteur et $x$ la circonférence. Commenter les résultats.

::: answer
On effectue la régression $y = \beta_1+\beta_2x+\varepsilon$ à l'aide de
la fonction `lm` disponible nativement dans
{{< iconify logos:r-lang >}}. On cherche ainsi une estimation de
$\beta_1$ et $\beta_2$ à l'aide de la méthode des moindres carrés
ordinaires (MCO).

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
fit_lm_eucalyptus <- lm(ht ~ circ, data = data_eucalyptus) 
summary(fit_lm_eucalyptus)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
fit_lm_eucalyptus <- lm(ht ~ circ, data = data_eucalyptus) 
summary(fit_lm_eucalyptus)
```
:::

Commentons la sortie détaillée donnée par la fonction générique
`summary`.

-   La première partie du tableau <tt>Residuals</tt> donne quelques
    statistiques descriptives sur la distribution des résidus de la
    régression linéaire Pour rappel, le résidu $\widehat{\varepsilon}_i$
    de l'observation $i$ est la différence entre la variable à expliquer
    $Y_i$ et la valeur ajustée de $Y_i$ par le modèle c'est à dire :

    $$
    \widehat{\varepsilon}_i = Y_i- \underbrace{(\widehat{\beta}_1 + \widehat{\beta}_2X_i)}_{\widehat{Y}_i}
    $$

-   La seconde partie notée <tt>Coefficients</tt> est présentée sous
    forme de tableau. Elle nous renseigne sur l'estimation des
    coefficients et la significativité de ces derniers sous l'hypothèse
    de gaussianité des erreurs. Ce tableau comporte autant de lignes que
    de coefficient à estimer dans le modèle de régression linéaire (ce
    nombre est noté $p$ dans le cours). Ici, il y a deux lignes car deux
    coefficients interviennent dans notre modélisation, la première
    ligne correspond à l'estimation de $\beta_1$ pour l'ordonnée à
    l'origine <tt>Intercept</tt>, et la deuxième sur l'estimation de
    $\beta_2$ , l'effet de la circonférence <tt>circ</tt> sur la hauteur
    de l'arbre.

    -   La première colonne (colonne <tt>Estimate</tt>) contient les
        estimations des paramètres i.e. les estimations
        $\widehat{\beta}_1 \approx 9,03$ et
        $\widehat{\beta}_2 \approx 0,26$.

        L'estimation du coefficient estimété $\widehat{\beta}_2$
        interprète de la manière suivante : "Lorsque la circonférence
        d'un arbre augmente d'un centimètre sa hauteur gagne 26
        centimètres."

    -   La seconde colonne ( <tt>Std. Error</tt>) contient les
        écarts-types estimés des estimateurs $\widehat{\beta}_1$ et
        $\widehat{\beta}_2$ . Ils sont donnés par

        $$
        \forall\ j \in \{1, \dots, p\}, \  \widehat{\sigma}_{\widehat{\beta}_j} = \widehat{\sigma}\sqrt{(X'X)^{-1}_{j,j}} \ \textrm{avec} \ \widehat{\sigma} = \sqrt{\frac{1}{n-p}\sum\limits_{i=1}^n \widehat{\varepsilon}_i^2}
        $$

    -   Dans la troisième colonne (<tt>t. value</tt>) figure la valeur
        observée de la statistique de test de Student d'hypothèse
        $H_0 : \beta_ j = 0$ contre $H_1 : \beta_j \neq 0$.

        ::: callout-important
        Ce test exact est valable uniquement sous l'hypothèse de
        normalité et indépendance des erreurs, c'est à dire si on
        suppose que :

        $$
        \varepsilon  = \begin{pmatrix} 
        \varepsilon_1 \\
        \vdots \\
        \varepsilon_n
        \end{pmatrix} \sim \mathcal{N}\left(0, \sigma^2 I_n \right)
        $$
        :::

        La statistique de test $T_j$ est donnée par

        $$
        T_j = \frac{{\widehat{\beta}}_j}{\widehat{\sigma}_{\widehat{\beta}_j}}
        $$

        Sous l'hypothèse nulle, la variable aléatoire $T_j$ suit une loi
        de Student à $n-p$ degrés de liberté (voir corollaire 2.2.10 du
        cours).

        On rejette $H_0$ pour un risque de première espèce $\alpha$ si
        $\left|T_j\right| > q_{1-\alpha/2}^{(\mathcal{T}_{n-p})}$. C'est
        le cas ici pour $\beta_1$ et $\beta_2$ au niveau $\alpha = 5 \%$
        : $$\begin{align*}
        \left|T_1\right| \approx 50,26 &>  q_{0,975}^{(\mathcal{T}_{1427})} \approx 1,961 \\
        \left|T_2\right| \approx 68,78 &>  q_{0,975}^{(\mathcal{T}_{1427})} \approx 1,961
        \end{align*}
        $$

    -   La quatrième colonne (colonne <tt>Pr(\>\|t\|)</tt>) contient la
        p-value pour ces mêmes tests de Student. C'est la probabilité
        pour la statistique de test sous $H_0$ de dépasser la valeur
        estimée c'est à dire explicitement :
        $$P(\mathcal{T}_{n-p}>|t|)=2\left(1-\mathcal{F}^{\mathcal{T}_{n-p}}(t)\right)$$

        De manière équivalente à la troisième colonne, ces tests de
        nullité des deux coefficients indiquent qu'ils semblent tous
        deux significativement non nuls (quand l'autre coefficient est
        fixé à la valeur estimée). En effet, les p-values sont bien
        inférieures au niveau de risque de première espèce $\alpha$
        fixé.

-   La ligne <tt>Residual standard error</tt> correspond à l'estimation
    de l'écart-type $\sigma$ des erreurs de modélisation $\varepsilon_i$
    . On lit donc $\widehat{\sigma} \approx 1,199$. Le nombre de degré
    de liberté inscrit sur la même ligne $n-p = 1~429-2 = 1~427$ car

    $$
    (n-p)\frac{\widehat{\sigma}}{\sigma} \sim \chi^2\left(n-p \right)
    $$

-   La ligne suivante donne la valeur du coefficient de détermination
    $R^2$ (<tt>Multiple R-squared</tt>). Il est définit par

    $$
    \begin{align*}
    R^2 &=\frac{SCE}{SCT}= \frac{\left\| \widehat{Y}-\overline{y}\mathbb{1}\right\|^2}{\left\| Y-\overline{y}\mathbb{1}\right\|^2} = \frac{\sum\limits_{i=1}^n \left(\widehat{y}_i-\overline{y_n} \right)^2}{\sum\limits_{i=1}^n \left(y_i-\overline{y_n} \right)^2} \\
    &= 1 - \frac{SCR}{SCT} = 1-\frac{\left\|\widehat{\varepsilon} \right\|^2}{\left\|Y - \overline{y_n}\mathbb{1}\right\|^2}=1-\frac{\sum\limits_{i=1}^n \widehat{\varepsilon}_i^2}{\sum\limits_{i=1}^n \left(y_i-\overline{y_n} \right)^2}
    \end{align*}
    $$

    On peut lire $R^2 \approx 0,77$. Cela signifie que 77 % de la
    variance des hauteurs des eucalyptus dans le jeu de données est
    expliquée par la circonférence.

    On trouve ensuite sur la même ligne le coefficient de détermination
    ajusté $R_a^2$ (<tt>Adjusted R-squared</tt>) défini par

    $$R_a^2=1-\frac{n-1}{n-p}\frac{SCR}{SCT} = 1-\frac{n-1}{n-p}\frac{\left\|\widehat{\varepsilon} \right\|^2}{\left\|Y - \overline{y_n}\mathbb{1}\right\|^2}=1-\frac{n-1}{n-p}\frac{\sum\limits_{i=1}^n \widehat{\varepsilon}_i^2}{\sum\limits_{i=1}^n \left(y_i-\overline{y_n} \right)^2}$$

    Cet ajustement permet de contrebalancer l'effet de l'ajout d'une
    variable dans la modélisation même non significative sur la valeur
    de ce coefficient. Comme $\frac{n-1}{n-p}$ est proche de 1 ici,
    $R_a^2$ et $R^2$ sont proches.

-   La dernière ligne pour la statistique de test $F$
    (<tt>F-Statistic</tt>), surtout utile en régression linéaire
    multiple, rend compte du test entre le modèle complet et le modèle
    ne contenant que la constante. Ce test permet de contrôler la
    significativité globale du modèle. Il n'est pas très utile ici car
    il est équivalent au test de Student $H_0 : \beta_2 = 0$ contre
    $H_1 : \beta_2 \neq 0$.
:::

## Question 3

Quelle est la formule théorique de $\hat{\beta}_1$ et $\hat{\beta}_2$ ?
Retrouver les estimations fournies par R en l’utilisant.

::: answer
Pour le modèle linéaire simple, on a :

$$
\begin{align*}
\widehat{\beta}_1 &= \overline{Y_n} -  \widehat{\beta}_2\overline{x_n} = \overline{Y}_n -  \frac{\textrm{Cov}(x, Y)}{\textrm{Var}(x)}\overline{x_n}\\
\widehat{\beta}_2 &=  \frac{\sum\limits_{i=1}^n \left(x_i-\overline{x_n}\right)\left(Y_i-\overline{Y_n}\right)}{\sum\limits_{i=1}^n \left(x_i-\overline{x_n}\right)^2}=\frac{\textrm{Cov}(x, Y)}{\textrm{Var}(x)} 
\end{align*}
$$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
y_bar <- mean(data_eucalyptus$ht)
x_bar <- mean(data_eucalyptus$circ)
cov_xy <- cov(data_eucalyptus$ht, data_eucalyptus$circ)
var_x <- var(data_eucalyptus$circ)
beta_2_hat <- cov_xy/var_x
beta_1_hat <- y_bar - beta_2_hat*x_bar
matrix(data = c(beta_1_hat, beta_2_hat), ncol = 1)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
y_bar <- mean(data_eucalyptus$ht)
x_bar <- mean(data_eucalyptus$circ)
cov_xy <- cov(data_eucalyptus$ht, data_eucalyptus$circ)
var_x <- var(data_eucalyptus$circ)
beta_2_hat <- cov_xy/var_x
beta_1_hat <- y_bar - beta_2_hat*x_bar
matrix(data = c(beta_1_hat, beta_2_hat), ncol = 1)
```
:::

Les résultats sont cohérents avec la sortie {{< iconify logos:r-lang >}}
de la fonction `lm`.

On pouvait raisonner aussi matriciellement . Plus généralement pour une
régression linéaire multiple, on a :

$$
\widehat{\beta} =  \begin{pmatrix} \widehat{\beta}_1 \\ \widehat{\beta}_2  \\ \end{pmatrix} = \left(X'X \right)^{-1}X'Y 
$$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
X <- cbind(1, data_eucalyptus$circ)
Y <- matrix(data = data_eucalyptus$ht, ncol=1)
solve(t(X)%*%X)%*%t(X)%*%Y


```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
X <- cbind(1, data_eucalyptus$circ)
Y <- matrix(data = data_eucalyptus$ht, ncol=1)
solve(t(X)%*%X)%*%t(X)%*%Y
```
:::

On retrouve les mêmes valeurs.
:::

## Question 4

Calculer un intervalle de confiance à 95 % pour $\beta_1$ et $\beta_2$, en supposant la normalité des données.

::: answer
La formule de l'intervalle de confiance pour le coefficient $\beta_j$
sous l'hypothèse d'erreurs gaussiennes, centrées et homoscédastiques est
: $$
I C_{1-\alpha}\left(\beta_j\right)=\left[\hat{\beta}_j \pm q_{1-\alpha/2}^{\mathcal{T}_{n-p}} \hat{\sigma}_{\hat{\beta}_j}\right]
$$ où
$\hat{\sigma}_{\hat{\beta}_j}=\hat{\sigma} \sqrt{\left(X^{\prime} X\right)_{j j}^{-1}}$
est l'estimateur de l'écart-type de $\hat{\beta}_j$.

En reportant les résultats du modèle de régression, on obtient pour
$\alpha=0,05\ \ %$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
beta_1_hat <- 9.037476
beta_2_hat <- 0.257138
sigma_beta_1_hat <- 0.179802
sigma_beta_2_hat <- 0.003738
qt975 <- qt(p = 0.975, df = nrow(data_eucalyptus)-2L)
matrix(
  data = c(
    beta_1_hat - qt975*sigma_beta_1_hat,
    beta_1_hat + qt975*sigma_beta_1_hat,
    beta_2_hat - qt975*sigma_beta_2_hat,
    beta_2_hat + qt975*sigma_beta_2_hat
  ),
  nrow = 2L,
  ncol = 2L,
  byrow = TRUE,
  dimnames = list(
    c("beta_1", "beta_2"),
    c("Borne inférieure de l'IC", "Borne supérieure de l'IC")
  )
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
beta_1_hat <- 9.037476
beta_2_hat <- 0.257138
sigma_beta_1_hat <- 0.179802
sigma_beta_2_hat <- 0.003738
qt975 <- qt(p = 0.975, df = nrow(data_eucalyptus)-2L)
matrix(
  data = c(
    beta_1_hat - qt975*sigma_beta_1_hat,
    beta_1_hat + qt975*sigma_beta_1_hat,
    beta_2_hat - qt975*sigma_beta_2_hat,
    beta_2_hat + qt975*sigma_beta_2_hat
  ),
  nrow = 2L,
  ncol = 2L,
  byrow = TRUE,
  dimnames = list(
    c("beta_1", "beta_2"),
    c("Borne inférieure de l'IC", "Borne supérieure de l'IC")
  )
)
```
:::

On peut aussi appliquer cette formule en récupérant les coefficients
estimés automatiquement à partir de l'objet {{< iconify logos:r-lang >}}
de l'estimation du modèle en sortie de la fonction `lm`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
beta_1_hat <- fit_lm_eucalyptus$coefficients[1]
beta_2_hat <- fit_lm_eucalyptus$coefficients[2]
sigma_beta_1_hat <- sqrt(vcov(fit_lm_eucalyptus)[1, 1])
sigma_beta_2_hat <- sqrt(vcov(fit_lm_eucalyptus)[2, 2])
qt975 <- qt(p = 0.975, df = nrow(data_eucalyptus)-2L)
matrix(
  data = c(
    beta_1_hat - qt975*sigma_beta_1_hat,
    beta_1_hat + qt975*sigma_beta_1_hat,
    beta_2_hat - qt975*sigma_beta_2_hat,
    beta_2_hat + qt975*sigma_beta_2_hat
  ),
  nrow = 2L,
  ncol = 2L,
  byrow = TRUE,
  dimnames = list(
    c("beta_1", "beta_2"),
    c("Borne inférieure de l'IC", "Borne supérieure de l'IC")
  )
)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
beta_1_hat <- fit_lm_eucalyptus$coefficients[1]
beta_2_hat <- fit_lm_eucalyptus$coefficients[2]
sigma_beta_1_hat <- sqrt(vcov(fit_lm_eucalyptus)[1, 1])
sigma_beta_2_hat <- sqrt(vcov(fit_lm_eucalyptus)[2, 2])
qt975 <- qt(p = 0.975, df = nrow(data_eucalyptus)-2L)
matrix(
  data = c(
    beta_1_hat - qt975*sigma_beta_1_hat,
    beta_1_hat + qt975*sigma_beta_1_hat,
    beta_2_hat - qt975*sigma_beta_2_hat,
    beta_2_hat + qt975*sigma_beta_2_hat
  ),
  nrow = 2L,
  ncol = 2L,
  byrow = TRUE,
  dimnames = list(
    c("beta_1", "beta_2"),
    c("Borne inférieure de l'IC", "Borne supérieure de l'IC")
  )
)
```
:::

On peut aussi utiliser directement la fonction `confint`.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
confint(fit_lm_eucalyptus)
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
confint(fit_lm_eucalyptus)
```
:::

Quelle que soit la méthode, on trouve :

$$
\begin{align*}
I C_{95\ \%}\left(\beta_1\right)&=\left[8,685\ ;\ 9,390\right] \\
I C_{95\ \%}\left(\beta_2\right)&=\left[0,250\ ;\ 0,264\right]
\end{align*}
$$
:::

## Question 5

Si le bruit $\epsilon$ ne suit pas une loi normale, les intervalles de confiance précédents restent-ils valables ?

::: answer
Pour que ces intervalles de confiances soient exacts, l'erreur doit être gausienne. Cependant, ils le deviennent asymptotiquement sous certaines conditions assez faible de régularité grâce au théorème central limite (cf. remarque slide 70 du cours). Comme, ici $n=1\ 429 \gg 30$ , on peut se fier à ces intervalles de confiance même si la normalité des erreurs n'est pas vérifiée.
:::

## Question 6

Tracer l’estimateur de la droite de régression et un intervalle de
confiance à 95 % de celle-ci. Que déduisez-vous de la qualité de
l’estimation ?

::: answer
::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
#| fig-align: center
plot(
  x = data_eucalyptus$circ,
  y = data_eucalyptus$ht,
  type = "p",
  xlab = "Circonférence",
  ylab = "Hauteur",
  pch = 3,
  col = "grey60"
)
abline(fit_lm_eucalyptus, col = "red")
newdata <- data.frame(circ = seq(from = 25, to = 70, by = 0.1))
confint_val <- predict(
  object = fit_lm_eucalyptus,
  newdata = newdata,
  interval = "confidence"
)

lines(newdata$circ, confint_val[, "lwr"], col = "red", lty = 2)
lines(newdata$circ, confint_val[, "upr"], col = "red", lty = 2)
grid()

```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
#| fig-align: center
newdata <- data.frame(circ = seq(from = 25, to = 80, by = 0.1))
confint_val <- predict(
  object = fit_lm_eucalyptus,
  newdata = newdata,
  interval = "confidence"
) |>
  tibble::as_tibble() |>
  cbind(newdata)

ggplot2::ggplot() +
  ggplot2::labs(x = "Circonférence", y = "Hauteur") + 
  ggplot2::geom_point(
    data = data_eucalyptus,
    mapping = aes(x = circ, y = ht),
    col = "grey70"
  ) + 
 ggplot2::geom_ribbon(
   data = confint_val,
   mapping = aes(ymin = lwr, ymax = upr, x = circ),
   fill = "red",
   alpha = 0.5
 ) +
 ggplot2::geom_abline(
    intercept = fit_lm_eucalyptus$coefficients[1],
    slope = fit_lm_eucalyptus$coefficients[2],
    col = "red"
  ) + 
 ggplot2::theme_light()
```
:::

On constate une faible incertitude sur la droite estimée.
:::

## Question 7

On veut à présent prédire la hauteur d’une nouvelle série d’eucalyptus de circonférences 50, 100, 150 et 200. Donner les estimateurs de la taille de chacun d’entre eux et les intervalles de prévision à 95 % associés, en supposant la normalité des données.

::: answer
La prévision $\widehat{y}_{n+1}^p$ pour une circonférence $x_{n+1}$ est
donnée par la formule
$$\widehat{y}_{n+1}^p = \widehat{\beta}_1+\widehat{\beta}_2x_{n+1}$$

Sous l'hypothèse de gaussianité des erreurs, un IC de $y_{n+1}$ est donné par
$$I C_{1-\alpha}\left(y_{n+1}\right)=\left[\widehat{y}_{n+1}^p \pm q_{1-\alpha/2}^{\mathcal{T}_{n-p}} \hat{\sigma}\sqrt{1+\frac{1}{n}+\frac{\left(x_{n+1}-\overline{x_n}\right)^2}{\sum\limits_{i=1}^n \left(x_i - \overline{x_n} \right)^2}}\right]$$

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
#| fig-align: center
n <- nrow(data_eucalyptus)
p <- 2L
beta_1_hat <- fit_lm_eucalyptus$coefficients[1] 
beta_2_hat <- fit_lm_eucalyptus$coefficients[2]
x_bar <- mean(data_eucalyptus$circ)
var_x <- var(data_eucalyptus$circ)
q975 <- qt(p = 0.975, df = n-p)
sigma_hat <- sigma(fit_lm_eucalyptus)

newdata <- data.frame(circ = c(50, 100, 150, 200))
newdata$hauteurs_predites <- beta_1_hat + newdata$circ*beta_2_hat
newdata$pm <- q975*sigma_hat*sqrt(1+1/n+(newdata$circ-x_bar)**2/(n*var_x))
newdata$borne_inf_pred <- newdata$hauteurs_predites - newdata$pm
newdata$borne_sup_pred <- newdata$hauteurs_predites + newdata$pm
newdata$pm <- NULL
newdata
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
#| fig-align: center
n <- nrow(data_eucalyptus)
p <- 2L
beta_1_hat <- fit_lm_eucalyptus$coefficients[1] 
beta_2_hat <- fit_lm_eucalyptus$coefficients[2]
x_bar <- mean(data_eucalyptus$circ)
var_x <- var(data_eucalyptus$circ)
q975 <- qt(p = 0.975, df = n-p)
sigma_hat <- sigma(fit_lm_eucalyptus)

newdata <- tibble::tibble(circ = c(50, 100, 150, 200)) |>
  dplyr::mutate(
    hauteurs_predites = beta_1_hat + circ*beta_2_hat,
    pm = q975*sigma_hat*sqrt(1+1/n+(circ-x_bar)**2/(n*var_x)),
    borne_inf_pred = hauteurs_predites - pm,
    borne_sup_pred = hauteurs_predites + pm 
) |>
  dplyr::select(-pm)

newdata
```
:::

On peut obtenir ces résultats plus simplement avec la fonction `predict`
avec l'option `interval="prediction"` qui permet de calculer les
intervalles de prévision autour des prévisions.

::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
#| fig-align: center

newdata <- data.frame(circ = c(50, 100, 150, 200))
predict(
  object = fit_lm_eucalyptus,
  newdata = newdata,
  interval = "prediction"
) |> as.data.frame()
```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
#| fig-align: center
newdata <- tibble::tibble(circ = c(50, 100, 150, 200))
predict(
  object = fit_lm_eucalyptus,
  newdata = newdata,
  interval = "prediction"
) |> tibble::as_tibble()
```
:::

On remarque que les intervalles de prévision sont plus élevés pour les
valeurs de circonférences loin de la moyenne des données. Pour rappel
l’erreur de prévision cumule deux erreurs :

-   l’erreur due à l’estimation de la droite (celle-ci est moins précise
    loin de la moyenne des données) ;
-   l’erreur due à $\varepsilon_{n+1}$: elle est stable quelle que soit
    la valeur de `circ` et incompressible car
    $\mathrm{Var}(\varepsilon_{n+1})=\sigma^2$.
:::

## Question 8

Ajouter à la représentation graphique de la question 6 les intervalles
de prévision (associés aux mêmes valeurs de la circonférence).

::: answer
::: {.panel-tabset group="language"}
### Base R

```{webr}
#| envir: baser
#| autorun: true
#| fig-align: center
plot(
  x = data_eucalyptus$circ,
  y = data_eucalyptus$ht,
  type = "p",
  xlab = "Circonférence",
  ylab = "Hauteur",
  pch = 3,
  col = "grey60"
)
abline(fit_lm_eucalyptus, col = "red")
newdata <- data.frame(circ = seq(from = 25, to = 70, by = 0.1))
confint_val <- predict(
  object = fit_lm_eucalyptus,
  newdata = newdata,
  interval = "confidence"
)

lines(newdata$circ, confint_val[, "lwr"], col = "red", lty = 2)
lines(newdata$circ, confint_val[, "upr"], col = "red", lty = 2)

predint_val <- predict(
  object = fit_lm_eucalyptus,
  newdata = newdata,
  interval = "prediction"
)

lines(newdata$circ, predint_val[, "lwr"], col = "blue", lty = 2)
lines(newdata$circ, predint_val[, "upr"], col = "blue", lty = 2)
grid()

```

### Tidyverse

```{webr}
#| envir: tdv
#| autorun: true
#| fig-align: center
newdata <- data.frame(circ = seq(from = 25, to = 80, by = 0.1))
confint_val <- predict(
  object = fit_lm_eucalyptus,
  newdata = newdata,
  interval = "confidence"
) |>
  tibble::as_tibble() |>
  cbind(newdata)
predint_val <- predict(
  object = fit_lm_eucalyptus,
  newdata = newdata,
  interval = "prediction"
) |>
  tibble::as_tibble() |>
  cbind(newdata)


ggplot2::ggplot() +
  ggplot2::labs(x = "Circonférence", y = "Hauteur") + 
  ggplot2::geom_point(
    data = data_eucalyptus,
    mapping = aes(x = circ, y = ht),
    col = "grey70"
  ) + 
 ggplot2::geom_ribbon(
   data = predint_val,
   mapping = aes(ymin = lwr, ymax = upr, x = circ),
   fill = "blue",
   alpha = 0.5
 ) +
 ggplot2::geom_ribbon(
   data = confint_val,
   mapping = aes(ymin = lwr, ymax = upr, x = circ),
   fill = "red",
   alpha = 0.5
 ) +
 ggplot2::geom_abline(
    intercept = fit_lm_eucalyptus$coefficients[1],
    slope = fit_lm_eucalyptus$coefficients[2],
    col = "red"
  ) + 
 ggplot2::theme_light()
```
:::
:::

## Question 9

Si le bruit $\epsilon$ ne suit pas une loi normale, les intervalles de prévision précédents restent-ils valables ?

::: answer
Non, les intervalles de confiance pour les prévisions ne sont plus du tout valable si l'hypothèse Gaussienne n'est plus vérifiée. Comme nous l'avons mentionné à la question 6, l’erreur de prévision cumule deux erreurs :

-   l’erreur due à l’estimation de la droite i.e. l'erreur liée à
    $\widehat{\beta}$. Cet estimateur suit asymptotiquement une loi
    gaussienne même si les erreurs ne sont pas gaussienne.
-   l’erreur due à $\varepsilon_{n+1}$ : cette erreur suit sa propre loi et il n'y a pas de convergence lorsque $n$ augmente.

À cause de cette deuxième erreur, $Y_{n+1}-\widehat{Y}_{n+1}$ ne suit pas une loi Gaussienne et donc les intervalles de confiance de la prédiction ne sont plus valables.
:::
