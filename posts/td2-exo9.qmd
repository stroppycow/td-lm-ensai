---
title: "TD 2 - Exercice 9 - Probabilit√© de sur-ajustement des crit√®res de s√©lection"
lang: fr
author: "Th√©o Leroy"
date: "17 octobre 2025"
params:
  question_courante: 0
format:
  live-html:
    code-background: true
    toc: true
    page-layout: full
editor: 
  mode: source
  markdown: 
    wrap: 72
fig-align: center
filters: 
  - diagram
  - custom-callout
custom-callout:    
  answer:
    color: "#CCCCCC"
    icon: true
    icon-symbol: "üìù"
    appearance: "default"
    title: "Correction"
---

{{< include ./../_extensions/conditionnal.qmd >}}
{{< include ./../_extensions/r-wasm/live/_knitr.qmd >}}

On se place dans le cadre de l‚Äôexercice pr√©c√©dent, mais on suppose de plus que la variable
$X^{(p)}$ n‚Äôest pas significative dans le mod√®le (i.e. son coefficient est nul dans la r√©gression)
et que les r√©sidus sont i.i.d. gaussiens. On admet les r√©sultats √©nonc√©s dans les questions
de l‚Äôexercice pr√©c√©dent.


## Question 1

Quelle loi suit la statistique $F$ ? Montrer que lorsque $n \to 1$, cette loi est √©quivalente
√† une loi $\chi^2(1)$.

::: {.content-visible when-meta="is_answer_print_1"}

::: answer

Si le mod√®le est Gaussien, alors sous $H_{0}: \beta_{p}=0, F$ suit une
loi $F(1, n-p)$.

Or par d√©finition d'une loi de Fisher,

$$
F(1, n-p)=\frac{\chi^{2}(1) / 1}{\chi^{2}(n-p) /(n-p)}
$$

En notant $U_{n}$ une variable al√©atoire suivant une loi
$\chi^{2}(n-p) /(n-p)$, on a la repr√©sentation

$$
U_{n}=\frac{1}{n-p} \sum_{i=1}^{n-p} Z_{i}^{2}
$$

o√π les $Z_{i}$ sont i.i.d. $\mathcal{N}(0,1)$.

Par application de la loi faible des grands nombres, on a donc
$U_{n} \rightarrow \mathbb{E}\left(Z_{1}^{2}\right)=1$ en probabilit√©.
D'apr√®s le lemme de Slutsky,
$n \rightarrow \infty, F(1, n-p) \rightarrow \chi^{2}(1)$ en loi.

:::

:::

## Question 2

Lors de la mise en oeuvre du test de Fisher des mod√®les emboit√©s au niveau $\alpha \in [0, 1]$,
quelle est la probabilit√© de d√©cider (√† tort) d‚Äôinclure la variable $X^{(p)}$ dans le mod√®le ?

::: {.content-visible when-meta="is_answer_print_2"}

::: answer

On d√©cide (√† tort) d'inclure la variable $X^{(p)}$ si
$F>f_{1, n-p}(1-\alpha)$ o√π $f_{1, n-p}(1-\alpha)$ est le quantile
d'ordre $1-\alpha$ d'une loi $F(1, n-p)$. La probabilit√© que cela se
produise vaut $\alpha$. $\alpha$ est l'erreur de premi√®re esp√®ce que
l'on choisit.

:::

:::

## Question 3

Vers quoi tend la probabilit√© pr√©c√©dente si on base la d√©cision sur le $R^2_a$ ?

::: {.content-visible when-meta="is_answer_print_3"}

::: answer

On inclut la variable $X^{(p)}$ selon le crit√®re du $R^{2}$ ajust√© si
$F>1$. En notant $F_{1, n-p}$ la fonction de r√©partition d'une
$F(1, n-p)$ et $F_{\chi^{2}(1)}$ la fonction de r√©partition d'une
$\chi^{2}(1)$, on a 

$$
\mathbb{P}(F>1)=1-F_{1, n-p}(1) \underset{n \rightarrow \infty}{\longrightarrow} 1-F_{\chi^{2}(1)}(1) \approx 0,32
$$

:::

:::

## Question 4

M√™me question si la d√©cision est bas√©e sur le $C_p$ de Mallows.

::: {.content-visible when-meta="is_answer_print_4"}

::: answer

On inclut la variable $X^{(p)}$ selon le crit√®re du $C_p$ de Mallows si
$F>2$. En notant $F_{1, n-p}$ la fonction de r√©partition d'une
$F(1, n-p)$ et $F_{\chi^{2}(1)}$ la fonction de r√©partition d'une
$\chi^{2}(1)$, on a

$$
\mathbb{P}(F>2)=1-F_{1, n-p}(2) \underset{n \rightarrow \infty}{\longrightarrow} 1-F_{\chi^{2}(1)}(2) \approx 0,16
$$

:::

:::

## Question 5

M√™me question si la d√©cision est bas√©e sur le crit√®re AIC.

::: {.content-visible when-meta="is_answer_print_5"}

::: answer

Le crit√®re AIC est similaire au crit√®re du $C_{p}$ de Mallows lorsque
$n \rightarrow \infty$, on obtient donc le m√™me r√©sultat que dans la
question pr√©c√©dente.

:::

:::

## Question 6

M√™me question si la d√©cision est bas√©e sur le crit√®re BIC.

::: {.content-visible when-meta="is_answer_print_6"}

::: answer

D'apr√®s la question 6 de l'exercice 8, quand $n$ est grand, on inclut
$X^{(p)}$ selon le BIC si $F>\log(n)$.


**Intuition :  ** $\mathbb{P}(F>\log n) \rightarrow 0$

Plus rigoureusement, comme $F$ d√©pend de $n$,
$\mathbb{P}(F>\log n) \rightarrow 0$ n'est pas si imm√©diat. On a vu que $F_{1, n-p}(x) \rightarrow F_{\chi^{2}(1)}(x)$
pour tout $x$ (c'est la convergence en loi). Les fonctions
$F_{\mathcal{F}(1, n-p)}(.)$ √©tant continues et croissantes, cette
convergence simple implique la convergence uniforme d'apr√®s le second
th√©or√®me de Dini. Ainsi,
$$\left\|F_{1, n-p}-F_{\chi^{2}(1)}\right\|_{\infty} \rightarrow 0$$

Donc,

$$
\begin{align*}
\mathbb{P}(F > \log(n)) &= 1 - F_{1, n-p}(\log(n)) \\
&=\left|F_{1, n-p}(\log n)-F_{\chi^{2}(1)}(\log n)+F_{\chi^{2}(1)}(\log n)-1\right| \\
&\leq\left|F_{1, n-p}(\log n)-F_{\chi^{2}(1)}(\log n)\right|+\left|F_{\chi^{2}(1)}(\log n)-1\right| \\
&\leq\left\|F_{1, n-p}-F_{\chi^{2}(1)}\right\|_{\infty}+\left|F_{\chi^{2}(1)}(\log n)-1\right|
\end{align*}
$$

Le premier terme tend vers 0 par convergence uniforme, et le second
aussi car $F_{\chi^{2}(1)}(x) \rightarrow 1$ lorsque
$x \rightarrow \infty$.

:::

:::

## Question 7

Quel crit√®re est-il pr√©f√©rable de choisir si l‚Äôon souhaite minimiser le risque d‚Äôinclure
une variable en trop dans le mod√®le¬†?

::: {.content-visible when-meta="is_answer_print_7"}

::: answer

Pour tous les crit√®res, √† l'exception du BIC, la probabilit√© de
s√©lectionner le mauvais mod√®le (celui incluant $X^{(p)}$) demeure
positive m√™me lorsque $n \rightarrow \infty$. Seul le BIC assure la
s√©lection du bon mod√®le lorsque $n \rightarrow \infty$, ce qui en fait
le crit√®re pr√©f√©rable sous cet aspect.

:::

:::
